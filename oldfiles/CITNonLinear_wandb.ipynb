{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast=open(\"yeast_residual_data_full_1000_gt_2.txt\",\"r\")\n",
    "\n",
    "\n",
    "\n",
    "#yeast data read \n",
    "L=[]\n",
    "A=[]\n",
    "B=[]\n",
    "for i in range(0,1000):\n",
    "  line=yeast.readline()\n",
    "  #line=line[1:-2] #remove double quotes \n",
    "  #param = [j for j in line.split()]\n",
    "  #print(param)\n",
    "  #chrname.append(param[1])\n",
    "  #g1.append(param[2])\n",
    "  #g2.append(param[3])\n",
    "  line=yeast.readline()\n",
    "  l = [j for j in line.split()]\n",
    "  L.append([int(i) for i in l])\n",
    "  line=yeast.readline()\n",
    "  a = [j for j in line.split()]\n",
    "  A.append([float(i) for i in a])\n",
    "  line=yeast.readline()\n",
    "  b = [j for j in line.split()]\n",
    "  B.append([float(i) for i in b])\n",
    "dataset_0 = [i for i in zip(L,A,B)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yeast data\n",
    "yeast=open(\"yeast_residual_data_full_1000_gt_1.txt\",\"r\")\n",
    "\n",
    "\n",
    "\n",
    "#yeast data read \n",
    "L=[]\n",
    "A=[]\n",
    "B=[]\n",
    "for i in range(0,1000):\n",
    "  line=yeast.readline()\n",
    "  #line=line[1:-2] #remove double quotes \n",
    "  #param = [j for j in line.split()]\n",
    "  #print(param)\n",
    "  #chrname.append(param[1])\n",
    "  #g1.append(param[2])\n",
    "  #g2.append(param[3])\n",
    "  line=yeast.readline()\n",
    "  l = [j for j in line.split()]\n",
    "  L.append([int(i) for i in l])\n",
    "  line=yeast.readline()\n",
    "  a = [j for j in line.split()]\n",
    "  A.append([float(i) for i in a])\n",
    "  line=yeast.readline()\n",
    "  b = [j for j in line.split()]\n",
    "  B.append([float(i) for i in b])\n",
    "dataset_1 = [i for i in zip(L,A,B)]\n",
    "\n",
    "#reshapefunction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qd6CiVe-jyEn",
    "outputId": "b4187c26-21ff-4edc-e194-db58fd55f233"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 18:29:10.080611: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-07 18:29:10.080632: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Concatenate\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import wandb\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.packages as rpackages\n",
    "nlcor=importr('nlcor')\n",
    "import rpy2.robjects.numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OxvAXLLFnl7d"
   },
   "outputs": [],
   "source": [
    "class MDN_module(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, neurons=15, components = 1):\n",
    "        super(MDN_module, self).__init__(name=\"MDN_module\")\n",
    "        self.neurons = neurons\n",
    "        self.components = components\n",
    "\n",
    "        #chaging activation to relu from linear, changin relu to sigmoid \n",
    "        for i in range(1,3):\n",
    "          s=\"self\"+\".h\"+str(i)+\"= Dense(neurons, activation=\\\"relu\\\", name=\"+\"'h\"+str(i)+\"')\"\n",
    "          exec(s)\n",
    "        self.alphas = Dense(components, activation=\"softmax\", name=\"alphas\")\n",
    "        self.mus = Dense(components, activation=\"linear\",name=\"mus\") \n",
    "        self.sigmas = Dense(components, activation=\"nnelu\",name=\"sigmas\") #activation changed from linear to default\n",
    "        self.pvec = Concatenate(name=\"pvec\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x=self.h1(inputs)\n",
    "        #x=self.inputA(inputs)\n",
    "        x=self.h2(x)\n",
    "        alpha_v = self.alphas(x)\n",
    "        mu_v = self.mus(x)\n",
    "        sigma_v = self.sigmas(x)\n",
    "        \n",
    "        return self.pvec([alpha_v,mu_v, sigma_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7DSPXmR1ogiH"
   },
   "outputs": [],
   "source": [
    "no_parameters=3\n",
    "components=1\n",
    "\n",
    "def nnelu(input):\n",
    "    \"\"\" Computes the Non-Negative Exponential Linear Unit\n",
    "    \"\"\"\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def slice_parameter_vectors(parameter_vector):\n",
    "    \"\"\" Returns an unpacked list of paramter vectors.\n",
    "    \"\"\"\n",
    "    return [parameter_vector[:,i*components:(i+1\n",
    "    )*components] for i in range(no_parameters)]\n",
    "\n",
    "def gnll_loss(y, parameter_vector):\n",
    "    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n",
    "    \"\"\"\n",
    "    alpha,mu,sigma = slice_parameter_vectors(parameter_vector) # Unpack parameter vectors\n",
    "    #tf.print(sigma)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "           mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "           components_distribution=tfd.Normal(\n",
    "           loc=mu,       \n",
    "           scale=sigma))\n",
    "    \n",
    "    \n",
    "    \n",
    "    log_likelihood =  gm.log_prob(tf.transpose(y)) # Evaluate log-probability of y \n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1) \n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': Activation(nnelu)})\n",
    "\n",
    "def gnll_eval(y,alpha, mu, sigma):\n",
    "    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n",
    "    \"\"\"\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,       \n",
    "            scale=sigma))\n",
    "    log_likelihood = gm.log_prob(tf.transpose(y))\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "\n",
    "def eval_mdn_model(x_test, y_test, mdn_model):\n",
    "    y_pred = mdn_model.predict(np.reshape(x_test,newshape=(len(x_test),-1)))\n",
    "    alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "    mdn_nll = gnll_eval(y_test.astype(np.float32),alpha, mu, sigma).numpy()\n",
    "    return mdn_nll\n",
    "#reshapefunction\n",
    "def reshapevar(X):\n",
    "  return np.reshape(X,newshape=(len(X),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T6sJ7ffirsnB"
   },
   "outputs": [],
   "source": [
    "def compute_loss(P,Q):\n",
    "  opt = tf.optimizers.Adam(1e-2)\n",
    "  mdn_PQ = MDN_module()\n",
    "  mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "  mdn_PQ.fit(x=reshapevar(P), y=np.array(Q).T,epochs=100,  batch_size=64,verbose=0)\n",
    "  return eval_mdn_model(P,Q,mdn_PQ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "X6V8X2QFpmC7"
   },
   "outputs": [],
   "source": [
    "def shuffleBtimes(P,Q,B):\n",
    "  loss=[]\n",
    "  for i in range(0,B):\n",
    "    loss.append(compute_loss(P,np.random.permutation(Q)))\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iUW3ikOHu6PO"
   },
   "outputs": [],
   "source": [
    "def LinearLABData():\n",
    "  L = np.random.binomial(1,0.5,1000)  \n",
    "  beta0 = np.ones(1000)-0.4\n",
    "  #beta1 = 0.5\n",
    "  beta1=3\n",
    "  beta2= 0.3\n",
    "  beta3=0.8\n",
    "  eps0 = np.random.standard_normal(1000)\n",
    "  eps1 = np.random.standard_normal(1000)\n",
    "  A = beta0 + beta1*L + eps0\n",
    "  B = beta2+ beta3*A+ eps1 \n",
    "  #plt.scatter(A,B)\n",
    "  #plt.title(\"A vs B\")\n",
    "  #plt.xlabel(\"A\")\n",
    "  #plt.ylabel(\"B\")\n",
    "  return [L,A,B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OOIw2i80ugk6"
   },
   "outputs": [],
   "source": [
    "#not using it now \n",
    "def residual(P,Q):\n",
    "  model=sm.OLS(Q,P).fit()\n",
    "  return model.resid\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yeast_name=\"\"\n",
    "def yeast_data(i,ind):\n",
    "    global yeast_name\n",
    "    yeast_name=\"yeast_\"+str(i)+\"_\"+str(ind)\n",
    "    ds = eval(\"dataset_\"+str(i)+\"[\"+str(ind)+\"]\")\n",
    "    L_dist = np.array(ds[0]) #np.array(ds[0])\n",
    "    A_dist = np.array(ds[1])\n",
    "    B_dist = np.array(ds[2])\n",
    "    #plt.scatter(A_dist,B_dist)\n",
    "    #plt.title(\"A vs B\")\n",
    "    #plt.xlabel(\"A\")\n",
    "    #plt.ylabel(\"B\")\n",
    "    return [L_dist,A_dist,B_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pvalue(original,loss_list):\n",
    "    return sum(i < original for i in loss_list)/len(loss_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maeaswar81\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-03-07 18:29:32.408852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-07 18:29:32.408871: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/birds/yeast_pvalue_demo/runs/g5peitb9\" target=\"_blank\">yeast_simplenn_groundtruth_0</a></strong> to <a href=\"https://wandb.ai/birds/yeast_pvalue_demo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/birds/yeast_pvalue_demo/runs/g5peitb9?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe1fe4f5ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "      name=\"yeast_simplenn_groundtruth_0\",\n",
    "      project=\"yeast_pvalue_demo\",\n",
    "      entity=\"birds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "8NWufrxKokcX",
    "outputId": "b8f25bde-64db-4b27-86fb-05f7a5cf39cc"
   },
   "outputs": [],
   "source": [
    "random.seed(24)\n",
    "shuffles=10\n",
    "for i in range(0,2):\n",
    "#L,A,B=LinearLABData()\n",
    "    L,A,B=yeast_data(0,i)\n",
    "    B_resid=residual(A,B)\n",
    "    A_shuffle=np.copy(A)\n",
    "    B_shuffle=np.copy(B)\n",
    "    B_resid_shuffle=np.copy(B_resid)\n",
    "    loss_list_LA=shuffleBtimes(L,A_shuffle,shuffles)\n",
    "    loss_list_LB=shuffleBtimes(L,B_shuffle,shuffles)\n",
    "    #loss_list_LindB_A=shuffleBtimes(L,B_resid_shuffle,shuffles) #conditional independence test\n",
    "    true_LA=compute_loss(L,A)\n",
    "    true_LB=compute_loss(L,B)\n",
    "    #print(true_LB)\n",
    "    #print(loss_list_LB)\n",
    "    loss_LA_p=calculate_pvalue(true_LA,loss_list_LA)\n",
    "    loss_LB_p=calculate_pvalue(true_LB,loss_list_LB)\n",
    "    loss_LA_mutual=mutual_info_regression(L.reshape(-1,1),A)\n",
    "    loss_LB_mutual=mutual_info_regression(L.reshape(-1,1),B)\n",
    "    loss_LA_spear=stats.spearmanr(L,A)[0]\n",
    "    loss_LB_spear=stats.spearmanr(L,B)[0]\n",
    "    loss_LA_pear=stats.pearsonr(L,A)[0]\n",
    "    loss_LB_pear=stats.pearsonr(L,B)[0]\n",
    "    loss_LA_nlcor=np.array(nlcor.nlcor(L,A)[0])[0]\n",
    "    loss_LB_nlcor=np.array(nlcor.nlcor(L,B)[0])[0]\n",
    "    \n",
    "    #true_LindB_A=compute_loss(L,B_resid)\n",
    "    wandb.log({\"dataset\":i,\"loss_LA_p\":loss_LA_p,\"loss_LB_p\":loss_LB_p,\"loss_LA_mutual\":loss_LA_mutual,\"loss_LB_mutual\":loss_LB_mutual,\"loss_LA_spear\":loss_LA_spear,\"loss_LB_spear\":loss_LB_spear,\"loss_LA_pear\":loss_LA_pear,\"loss_LB_pear\":loss_LB_pear,\"loss_LA_nlcor\":loss_LA_nlcor,\"loss_LB_nlcor\":loss_LB_nlcor,\"true_LA\":true_LA,\"true_LB\":true_LB})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 103865... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dataset</td><td>▁█</td></tr><tr><td>loss_LA_mutual</td><td>▁█</td></tr><tr><td>loss_LA_nlcor</td><td>▁█</td></tr><tr><td>loss_LA_p</td><td>▁▁</td></tr><tr><td>loss_LA_pear</td><td>█▁</td></tr><tr><td>loss_LA_spear</td><td>█▁</td></tr><tr><td>loss_LB_mutual</td><td>▁█</td></tr><tr><td>loss_LB_nlcor</td><td>▁█</td></tr><tr><td>loss_LB_p</td><td>█▁</td></tr><tr><td>loss_LB_pear</td><td>▁█</td></tr><tr><td>loss_LB_spear</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dataset</td><td>1</td></tr><tr><td>loss_LA_mutual</td><td>0.0129</td></tr><tr><td>loss_LA_nlcor</td><td>0.15494</td></tr><tr><td>loss_LA_p</td><td>0.0</td></tr><tr><td>loss_LA_pear</td><td>-0.15494</td></tr><tr><td>loss_LA_spear</td><td>-0.15523</td></tr><tr><td>loss_LB_mutual</td><td>0.01045</td></tr><tr><td>loss_LB_nlcor</td><td>0.09204</td></tr><tr><td>loss_LB_p</td><td>0.2</td></tr><tr><td>loss_LB_pear</td><td>-0.01424</td></tr><tr><td>loss_LB_spear</td><td>-0.00614</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">yeast_simplenn_groundtruth_0</strong>: <a href=\"https://wandb.ai/birds/yeast_pvalue_demo/runs/g5peitb9\" target=\"_blank\">https://wandb.ai/birds/yeast_pvalue_demo/runs/g5peitb9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220307_182931-g5peitb9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CITNonLinear.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
