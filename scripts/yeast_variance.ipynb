{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/')\n",
    "import time\n",
    "from scipy import stats\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from nlcd_user import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## making table of non linearity using ks test ##########\n",
    "genotype=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/genotypes_binary_strongest_eqtl.csv\",header=0,index_col=0)\n",
    "expression_data=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/expression_statsmodels_linreg_residuals_01.csv\",index_col=0,header=0)\n",
    "causal_conf=read_configuration(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/yeastgt_1_wilko1752_ready.txt\")\n",
    "indp_conf=read_configuration(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/yeastgt_0_wilko1752_ready.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineardata=read_data(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/data/Linear500.txt\")\n",
    "sinedata=read_data(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/data/Sine500.txt\")\n",
    "sawdata=read_data(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/data/Saw500.txt\")\n",
    "paradata=read_data(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/data/Para500.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ks_yeast(conf):\n",
    "    total=[]\n",
    "    for  i in range(len(conf)):\n",
    "        trio=conf.iloc[i,]\n",
    "        L_name=trio[0]\n",
    "        A_name=trio[1]\n",
    "        B_name=trio[2]\n",
    "        L=genotype.loc[:,L_name]\n",
    "        A=expression_data.loc[:,A_name]\n",
    "        B=expression_data.loc[:,B_name]\n",
    "        unique_values = np.unique(L)\n",
    "        indv=[]\n",
    "        for value in unique_values:\n",
    "            indices = np.where(L == value)[0]\n",
    "            A_value = A[indices]    \n",
    "            indv.extend(lilliefors(A_value))\n",
    "            #indv.append(stats.shapiro(A_value)[1])\n",
    "        for value in unique_values:\n",
    "            indices = np.where(L == value)[0]\n",
    "            B_value = B[indices]    \n",
    "            indv.extend(lilliefors(B_value))\n",
    "        total.append(indv)\n",
    "    ks_result=pd.DataFrame(total,columns=['A|L = 0 stat','A|L = 0 p','A|L = 1 stat','A|L = 1 p','B|L = 0 stat','B|L = 0 p','B|L = 1 stat','B|L = 1 p',])\n",
    "    return ks_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ks_simdata(data):\n",
    "    total=[]\n",
    "    for  i in range(len(data)):\n",
    "        L=data[i][0]\n",
    "        A=data[i][1]\n",
    "        B=data[i][2]\n",
    "        unique_values = np.unique(L)\n",
    "        indv=[]\n",
    "        for value in unique_values:\n",
    "            indices = np.where(L == value)[0]\n",
    "            A_value = A[indices]    \n",
    "            indv.extend(lilliefors(A_value))\n",
    "        for value in unique_values:\n",
    "            indices = np.where(L == value)[0]\n",
    "            B_value = B[indices]    \n",
    "            indv.extend(lilliefors(B_value))\n",
    "        total.append(indv)\n",
    "    ks_result=pd.DataFrame(total,columns=['A|L = 0 stat','A|L = 0 p','A|L = 1 stat','A|L = 1 p','B|L = 0 stat','B|L = 0 p','B|L = 1 stat','B|L = 1 p',])\n",
    "    return ks_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff_plot(ks_result):\n",
    "    cutoffs=[0,0.01,0.02,0.03,0.05,0.06,0.07,0.08,0.09,0.1]\n",
    "    A_passed=[]\n",
    "    B_passed=[]\n",
    "    both=[]\n",
    "    for cutoff in cutoffs:\n",
    "        ks_result['A_passed']= (ks_result['A|L = 0 p']>=cutoff)& (ks_result['A|L = 1 p']>=cutoff)\n",
    "        ks_result['B_passed']=(ks_result['B|L = 0 p']>=cutoff) & (ks_result['B|L = 1 p']>=cutoff)\n",
    "        ks_result['both']=ks_result['A_passed'] & ks_result['B_passed']\n",
    "        A_passed.append(sum(ks_result['A_passed']))\n",
    "        B_passed.append(sum(ks_result['B_passed']))\n",
    "        both.append(sum(ks_result['both']))\n",
    "    finaltable=pd.DataFrame({'cutoffs':cutoffs,'A passed':A_passed,'B_passed':B_passed,'both':both})\n",
    "    return finaltable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeasttable_indp=cutoff_plot(calculate_ks_yeast(indp_conf))\n",
    "yeasttable_causal=cutoff_plot(calculate_ks_yeast(causal_conf))\n",
    "linear_table=cutoff_plot(calculate_ks_simdata(lineardata))\n",
    "sine_table=cutoff_plot(calculate_ks_simdata(sinedata))\n",
    "saw_table=cutoff_plot(calculate_ks_simdata(sawdata))\n",
    "para_table=cutoff_plot(calculate_ks_simdata(paradata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoffs</th>\n",
       "      <th>A passed</th>\n",
       "      <th>B_passed</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>97</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>97</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>93</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06</td>\n",
       "      <td>93</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.07</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.08</td>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.09</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>85</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cutoffs  A passed  B_passed  both\n",
       "0     0.00       100       100   100\n",
       "1     0.01        98        14    14\n",
       "2     0.02        97        13    13\n",
       "3     0.03        97        13    13\n",
       "4     0.05        93        10    10\n",
       "5     0.06        93         9     9\n",
       "6     0.07        92         9     9\n",
       "7     0.08        88         9     9\n",
       "8     0.09        87         9     9\n",
       "9     0.10        85         9     9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksresult=calculate_ks_simdata(paradata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simresult=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/2way/SawKRR500s100perm.csv\")\n",
    "simresult_rev=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/2way/SawKRR500s100perm_rev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plots not required anymore\n",
    "# simresult=pd.read_csv(\"./../../../conclude/newmethod/simulation_final/results/journal/simulation/nlcd/ParaKRR500s100perm.csv\")\n",
    "# fig, axs = plt.subplots(2,2)\n",
    "# fig.set_figheight(8)\n",
    "# fig.set_figwidth(8)\n",
    "# fig.suptitle(\"Para data\")\n",
    "# axs[0,0].scatter(ksresult['B|L = 1 stat'],simresult['p_final']  )\n",
    "# axs[0,0].set_xlabel(\"B|L = 1 liliferos statistic\")\n",
    "# axs[0,0].set_ylabel(\"p value A -> B\")\n",
    "# axs[0,1].scatter(ksresult['B|L = 0 stat'],simresult['p_final']  )\n",
    "# axs[0,1].set_xlabel(\"B|L = 0 liliferos statistic\")\n",
    "# axs[0,1].set_ylabel(\"p value A -> B\")\n",
    "# axs[1,0].scatter(ksresult['B|L = 1 p'],simresult['p_final']  )\n",
    "# axs[1,0].set_xlabel(\"B|L = 1 lilliferos p value\")\n",
    "# axs[1,0].set_ylabel(\"p value A -> B\")\n",
    "# axs[1,1].scatter(ksresult['B|L = 0 p'],simresult['p_final']  )\n",
    "# axs[1,1].set_xlabel(\"B|L = 0 lilliferos p value\")\n",
    "# axs[1,1].set_ylabel(\"p value A -> B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 2)\n",
    "# fig.set_figheight(8)\n",
    "# fig.set_figwidth(8)\n",
    "# fig.suptitle(\"Para data\")\n",
    "# axs[0,0].scatter(ksresult['B|L = 1 stat'],simresult['p_final']  )\n",
    "# axs[0,0].set_xlabel(\"B|L = 1 liliferos statistic\")\n",
    "# axs[0,0].set_ylabel(\"p value A -> B\")\n",
    "# axs[0,1].scatter(ksresult['B|L = 0 stat'],simresult['p_final']  )\n",
    "# axs[0,1].set_xlabel(\"B|L = 0 liliferos statistic\")\n",
    "# axs[0,1].set_ylabel(\"p value A -> B\")\n",
    "# axs[1,0].scatter(ksresult['B|L = 1 stat'],simresult_rev['p_final']  )\n",
    "# axs[1,0].set_xlabel(\"B|L = 1 liliferos statistic\")\n",
    "# axs[1,0].set_ylabel(\"p value B -> A\")\n",
    "# axs[1,1].scatter(ksresult['B|L = 0 stat'],simresult_rev['p_final']  )\n",
    "# axs[1,1].set_xlabel(\"B|L = 0 liliferos statistic\")\n",
    "# axs[1,1].set_ylabel(\"p value B -> A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 2)\n",
    "# fig.set_figheight(8)\n",
    "# fig.set_figwidth(8)\n",
    "# fig.suptitle(\"Saw data\")\n",
    "# axs[0,0].scatter(ksresult['B|L = 1 p'],simresult['p_final']  )\n",
    "# axs[0,0].set_xlabel(\"B|L = 1 lilliferos p value\")\n",
    "# axs[0,0].set_ylabel(\"p value A -> B\")\n",
    "# axs[0,1].scatter(ksresult['B|L = 0 p'],simresult['p_final']  )\n",
    "# axs[0,1].set_xlabel(\"B|L = 0 lilliferos p value\")\n",
    "# axs[0,1].set_ylabel(\"p value A -> B\")\n",
    "# axs[1,0].scatter(ksresult['B|L = 1 p'],simresult_rev['p_final']  )\n",
    "# axs[1,0].set_xlabel(\"B|L = 1 lilliferos p value\")\n",
    "# axs[1,0].set_ylabel(\"p value B -> A\")\n",
    "# axs[1,1].scatter(ksresult['B|L = 0 p'],simresult_rev['p_final']  )\n",
    "# axs[1,1].set_xlabel(\"B|L = 0 lilliferos p value\")\n",
    "# axs[1,1].set_ylabel(\"p value B -> A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L=data[98][0]\n",
    "# B=data[98][2]\n",
    "# indices = np.where(L == 1)[0]\n",
    "# B_value = B[indices]    \n",
    "# plt.hist(B_value)\n",
    "# lilliefors(B_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff=0.05\n",
    "# ks_result['A_passed']= (ks_result['A|L = 0 p']>=cutoff)& (ks_result['A|L = 1 p']>=cutoff)\n",
    "# ks_result['B_passed']=(ks_result['B|L = 0 p']>=cutoff) & (ks_result['B|L = 1 p']>=cutoff)\n",
    "# ks_result['both']=ks_result['A_passed'] & ks_result['B_passed']\n",
    "# ks_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simresult=pd.read_csv(\"./../../../conclude/newmethod/simulation_final/results/journal/2way/LinearKRR500s100perm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simresult_rev=pd.read_csv(\"./../../../conclude/newmethod/simulation_final/results/journal/2way/LinearKRR500s100perm_rev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lilliefors(x,dist='norm') # by default the distribution is normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ks_result['B|L = 1 stat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the number of trios that pass where liliferos test <0.05 and p value < 0.05 for the variable A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0]\n",
      " [72  5]]\n",
      "p value of A->B < 0.05 and liliferos test < 0.05 =  5\n",
      "p value of A->B < 0.05 and liliferos test >= than 0.05 =  72\n",
      "p value of A->B >= 0.05 and liliferos test < than 0.05 =  0\n",
      "p value of A->B >= 0.05 and liliferos test  >= 0.05 =  23\n"
     ]
    }
   ],
   "source": [
    "#make the confusion matrix \n",
    "#linear data \n",
    "from sklearn.metrics import confusion_matrix\n",
    "df=calculate_ks_simdata(lineardata)\n",
    "df_result=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/simulation/nlcd/LinearKRR500s100perm.csv\")\n",
    "df['A_final']=np.minimum(df['A|L = 0 p'],df['A|L = 1 p'])\n",
    "print(confusion_matrix(df_result['p_final']<0.05,df['A_final']<0.05))\n",
    "print('p value of A->B < 0.05 and liliferos test < 0.05 = ',sum((df_result['p_final']<0.05) & (df['A_final']<0.05)))\n",
    "print('p value of A->B < 0.05 and liliferos test >= than 0.05 = ',sum((df_result['p_final']<0.05) & (df['A_final']>=0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test < than 0.05 = ' ,sum((df_result['p_final']>=0.05) & (df['A_final']<0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test  >= 0.05 = ',sum((df_result['p_final']>=0.05) & (df['A_final']>=0.05)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58  6]\n",
      " [35  1]]\n",
      "p value of A->B < 0.05 and liliferos test < 0.05 =  1\n",
      "p value of A->B < 0.05 and liliferos test >= than 0.05 =  35\n",
      "p value of A->B >= 0.05 and liliferos test < than 0.05 =  6\n",
      "p value of A->B >= 0.05 and liliferos test  >= 0.05 =  58\n"
     ]
    }
   ],
   "source": [
    "#make the confusion matrix \n",
    "#sine data \n",
    "from sklearn.metrics import confusion_matrix\n",
    "df=calculate_ks_simdata(sinedata)\n",
    "df_result=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/simulation/nlcd/SineKRR500s100perm.csv\")\n",
    "df['A_final']=np.minimum(df['A|L = 0 p'],df['A|L = 1 p'])\n",
    "print(confusion_matrix(df_result['p_final']<0.05,df['A_final']<0.05))\n",
    "print('p value of A->B < 0.05 and liliferos test < 0.05 = ',sum((df_result['p_final']<0.05) & (df['A_final']<0.05)))\n",
    "print('p value of A->B < 0.05 and liliferos test >= than 0.05 = ',sum((df_result['p_final']<0.05) & (df['A_final']>=0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test < than 0.05 = ' ,sum((df_result['p_final']>=0.05) & (df['A_final']<0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test  >= 0.05 = ',sum((df_result['p_final']>=0.05) & (df['A_final']>=0.05)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72  7]\n",
      " [20  1]]\n",
      "p value of A->B < 0.05 and liliferos test < 0.05 =  1\n",
      "p value of A->B < 0.05 and liliferos test >= than 0.05 =  20\n",
      "p value of A->B >= 0.05 and liliferos test < than 0.05 =  7\n",
      "p value of A->B >= 0.05 and liliferos test  >= 0.05 =  72\n"
     ]
    }
   ],
   "source": [
    "#make the confusion matrix \n",
    "#saw data \n",
    "from sklearn.metrics import confusion_matrix\n",
    "df=calculate_ks_simdata(sawdata)\n",
    "df_result=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/simulation/nlcd/SawKRR500s100perm.csv\")\n",
    "df['A_final']=np.minimum(df['A|L = 0 p'],df['A|L = 1 p'])\n",
    "print(confusion_matrix(df_result['p_final']<0.05,df['A_final']<0.05))\n",
    "print('p value of A->B < 0.05 and liliferos test < 0.05 = ',sum((df_result['p_final']<0.05) & (df['A_final']<0.05)))\n",
    "print('p value of A->B < 0.05 and liliferos test >= than 0.05 = ',sum((df_result['p_final']<0.05) & (df['A_final']>=0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test < than 0.05 = ' ,sum((df_result['p_final']>=0.05) & (df['A_final']<0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test  >= 0.05 = ',sum((df_result['p_final']>=0.05) & (df['A_final']>=0.05)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  1]\n",
      " [76  4]]\n",
      "p value of A->B < 0.05 and liliferos test < 0.05 =  4\n",
      "p value of A->B < 0.05 and liliferos test >= than 0.05 =  76\n",
      "p value of A->B >= 0.05 and liliferos test < than 0.05 =  1\n",
      "p value of A->B >= 0.05 and liliferos test  >= 0.05 =  19\n"
     ]
    }
   ],
   "source": [
    "#make the confusion matrix \n",
    "#parabola data \n",
    "from sklearn.metrics import confusion_matrix\n",
    "df=calculate_ks_simdata(lineardata)\n",
    "df_result=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/simulation/nlcd/ParaKRR500s100perm.csv\")\n",
    "df['A_final']=np.minimum(df['A|L = 0 p'],df['A|L = 1 p'])\n",
    "print(confusion_matrix(df_result['p_final']<0.05,df['A_final']<0.05))\n",
    "print('p value of A->B < 0.05 and liliferos test < 0.05 = ',sum((df_result['p_final']<0.05) & (df['A_final']<0.05)))\n",
    "print('p value of A->B < 0.05 and liliferos test >= than 0.05 = ',sum((df_result['p_final']<0.05) & (df['A_final']>=0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test < than 0.05 = ' ,sum((df_result['p_final']>=0.05) & (df['A_final']<0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test  >= 0.05 = ',sum((df_result['p_final']>=0.05) & (df['A_final']>=0.05)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the number of trios that pass where liliferos test <0.05 and p value < 0.05 for the variable B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  1]\n",
      " [73  4]]\n",
      "p value of A->B < 0.05 and liliferos test < 0.05 =  4\n",
      "p value of A->B < 0.05 and liliferos test >= than 0.05 =  73\n",
      "p value of A->B >= 0.05 and liliferos test < than 0.05 =  1\n",
      "p value of A->B >= 0.05 and liliferos test  >= 0.05 =  22\n"
     ]
    }
   ],
   "source": [
    "#make the confusion matrix \n",
    "#linear data \n",
    "from sklearn.metrics import confusion_matrix\n",
    "df=calculate_ks_simdata(lineardata)\n",
    "df_result=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/simulation/nlcd/LinearKRR500s100perm.csv\")\n",
    "df['B_final']=np.minimum(df['B|L = 0 p'],df['B|L = 1 p'])\n",
    "print(confusion_matrix(df_result['p_final']<0.05,df['B_final']<0.05))\n",
    "print('p value of A->B < 0.05 and liliferos test < 0.05 = ',sum((df_result['p_final']<0.05) & (df['B_final']<0.05)))\n",
    "print('p value of A->B < 0.05 and liliferos test >= than 0.05 = ',sum((df_result['p_final']<0.05) & (df['B_final']>=0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test < than 0.05 = ' ,sum((df_result['p_final']>=0.05) & (df['B_final']<0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test  >= 0.05 = ',sum((df_result['p_final']>=0.05) & (df['B_final']>=0.05)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37 27]\n",
      " [21 15]]\n",
      "p value of A->B < 0.05 and liliferos test < 0.05 =  15\n",
      "p value of A->B < 0.05 and liliferos test >= than 0.05 =  21\n",
      "p value of A->B >= 0.05 and liliferos test < than 0.05 =  27\n",
      "p value of A->B >= 0.05 and liliferos test  >= 0.05 =  37\n"
     ]
    }
   ],
   "source": [
    "#make the confusion matrix \n",
    "#sine data \n",
    "from sklearn.metrics import confusion_matrix\n",
    "df=calculate_ks_simdata(sinedata)\n",
    "df_result=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/simulation/nlcd/SineKRR500s100perm.csv\")\n",
    "df['B_final']=np.minimum(df['B|L = 0 p'],df['B|L = 1 p'])\n",
    "print(confusion_matrix(df_result['p_final']<0.05,df['B_final']<0.05))\n",
    "print('p value of A->B < 0.05 and liliferos test < 0.05 = ',sum((df_result['p_final']<0.05) & (df['B_final']<0.05)))\n",
    "print('p value of A->B < 0.05 and liliferos test >= than 0.05 = ',sum((df_result['p_final']<0.05) & (df['B_final']>=0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test < than 0.05 = ' ,sum((df_result['p_final']>=0.05) & (df['B_final']<0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test  >= 0.05 = ',sum((df_result['p_final']>=0.05) & (df['B_final']>=0.05)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65 14]\n",
      " [ 7 14]]\n",
      "p value of A->B < 0.05 and liliferos test < 0.05 =  14\n",
      "p value of A->B < 0.05 and liliferos test >= than 0.05 =  7\n",
      "p value of A->B >= 0.05 and liliferos test < than 0.05 =  14\n",
      "p value of A->B >= 0.05 and liliferos test  >= 0.05 =  65\n"
     ]
    }
   ],
   "source": [
    "#make the confusion matrix \n",
    "#saw data \n",
    "from sklearn.metrics import confusion_matrix\n",
    "df=calculate_ks_simdata(sawdata)\n",
    "df_result=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/simulation/nlcd/SawKRR500s100perm.csv\")\n",
    "df['B_final']=np.minimum(df['B|L = 0 p'],df['B|L = 1 p'])\n",
    "print(confusion_matrix(df_result['p_final']<0.05,df['B_final']<0.05))\n",
    "print('p value of A->B < 0.05 and liliferos test < 0.05 = ',sum((df_result['p_final']<0.05) & (df['B_final']<0.05)))\n",
    "print('p value of A->B < 0.05 and liliferos test >= than 0.05 = ',sum((df_result['p_final']<0.05) & (df['B_final']>=0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test < than 0.05 = ' ,sum((df_result['p_final']>=0.05) & (df['B_final']<0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test  >= 0.05 = ',sum((df_result['p_final']>=0.05) & (df['B_final']>=0.05)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  0]\n",
      " [75  5]]\n",
      "p value of A->B < 0.05 and liliferos test < 0.05 =  5\n",
      "p value of A->B < 0.05 and liliferos test >= than 0.05 =  75\n",
      "p value of A->B >= 0.05 and liliferos test < than 0.05 =  0\n",
      "p value of A->B >= 0.05 and liliferos test  >= 0.05 =  20\n"
     ]
    }
   ],
   "source": [
    "#make the confusion matrix \n",
    "#parabola data \n",
    "from sklearn.metrics import confusion_matrix\n",
    "df=calculate_ks_simdata(lineardata)\n",
    "df_result=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/conclude/newmethod/simulation_final/results/journal/simulation/nlcd/ParaKRR500s100perm.csv\")\n",
    "df['B_final']=np.minimum(df['B|L = 0 p'],df['B|L = 1 p'])\n",
    "print(confusion_matrix(df_result['p_final']<0.05,df['B_final']<0.05))\n",
    "print('p value of A->B < 0.05 and liliferos test < 0.05 = ',sum((df_result['p_final']<0.05) & (df['B_final']<0.05)))\n",
    "print('p value of A->B < 0.05 and liliferos test >= than 0.05 = ',sum((df_result['p_final']<0.05) & (df['B_final']>=0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test < than 0.05 = ' ,sum((df_result['p_final']>=0.05) & (df['B_final']<0.05)))\n",
    "print('p value of A->B >= 0.05 and liliferos test  >= 0.05 = ',sum((df_result['p_final']>=0.05) & (df['B_final']>=0.05)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next cells are for sergregation of dataset based on variance of A which are further used in barplots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "commontfs=pd.read_csv('/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/commontfs.csv',header=None)[0].to_list()\n",
    "df=pd.read_csv('/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/strongest_eqtls_r_3columns.csv',header=0)\n",
    "df.drop(columns=df.columns[[0,3]], axis=1,  inplace=True)\n",
    "df.columns=['cis','pmarker']\n",
    "reqd=df[df['cis'].isin(commontfs)].reset_index()\n",
    "reqd.drop(columns=reqd.columns[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the genotype ## \n",
    "genotype=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/genotypes_binary_strongest_eqtl.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_data=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/expression_statsmodels_linreg_residuals_01.csv\",index_col=0,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cis</th>\n",
       "      <th>pmarker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YBL005W</td>\n",
       "      <td>chrII:216631_A/G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YBR083W</td>\n",
       "      <td>chrII:408801_T/C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YBR239C</td>\n",
       "      <td>chrII:699675_T/C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YCR065W</td>\n",
       "      <td>chrIII:236451_G/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YCR084C</td>\n",
       "      <td>chrIII:262264_T/C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>YOR363C</td>\n",
       "      <td>chrXV:1023392_T/G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>YPL038W</td>\n",
       "      <td>chrXVI:481979_C/T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>YPL133C</td>\n",
       "      <td>chrXVI:310970_A/C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>YPL248C</td>\n",
       "      <td>chrXVI:81157_G/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>YPR008W</td>\n",
       "      <td>chrXVI:566316_G/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cis            pmarker\n",
       "0   YBL005W   chrII:216631_A/G\n",
       "1   YBR083W   chrII:408801_T/C\n",
       "2   YBR239C   chrII:699675_T/C\n",
       "3   YCR065W  chrIII:236451_G/A\n",
       "4   YCR084C  chrIII:262264_T/C\n",
       "..      ...                ...\n",
       "75  YOR363C  chrXV:1023392_T/G\n",
       "76  YPL038W  chrXVI:481979_C/T\n",
       "77  YPL133C  chrXVI:310970_A/C\n",
       "78  YPL248C   chrXVI:81157_G/A\n",
       "79  YPR008W  chrXVI:566316_G/A\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the variance for each value of L \n",
    "var_list=[]\n",
    "for i in range(len(reqd)):\n",
    "    L=genotype.loc[:,reqd.loc[i,'pmarker']]\n",
    "    A=expression_data.loc[:,reqd.loc[i,'cis']]\n",
    "    unique_values = np.unique(L)\n",
    "    variance = []\n",
    "\n",
    "    for value in unique_values:\n",
    "        indices = np.where(L == value)[0]\n",
    "        A_value = A[indices]\n",
    "        variance.append(np.var(A_value))\n",
    "    var_list.append(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqd[['A_0','A_1']]=var_list\n",
    "reqd['absdifference']=abs((reqd['A_0']-reqd['A_1'])/reqd['A_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752\n",
      "1752\n",
      "1465\n",
      "1465\n",
      "1401\n",
      "1401\n",
      "1356\n",
      "1356\n",
      "623\n",
      "623\n",
      "581\n",
      "581\n",
      "574\n",
      "574\n",
      "516\n",
      "516\n",
      "297\n",
      "297\n"
     ]
    }
   ],
   "source": [
    "cutoffs=[0,0.05,0.1,0.125,0.15,0.175,0.2,0.225,0.25]\n",
    "for i in cutoffs:\n",
    "    varmore=reqd.loc[reqd['absdifference']>=i,]\n",
    "    causal=read_configuration(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/yeastgt_1_wilko1752_ready.txt\")\n",
    "    causal=causal.reset_index()\n",
    "    causal.columns=['id','L','A','B']\n",
    "    merged_table = pd.merge(varmore,causal, left_on=['cis', 'pmarker'], right_on=['A', 'L'])\n",
    "    print(len(merged_table))\n",
    "    np.savetxt(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/var_indices/yeast_wilko_var_causal_\"+str(i)+\".csv\",\n",
    "        merged_table['id'],\n",
    "        delimiter =\", \",\n",
    "        fmt ='% s')\n",
    "    indep=read_configuration(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/yeastgt_0_wilko1752_ready.txt\")\n",
    "    indep=indep.reset_index()\n",
    "    indep.columns=['id','L','A','B']\n",
    "    merged_table = pd.merge(varmore,indep, left_on=['cis', 'pmarker'], right_on=['A', 'L'])\n",
    "    print(len(merged_table))\n",
    "    np.savetxt(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/var_indices/yeast_wilko_var_indep_\"+str(i)+\".csv\",\n",
    "        merged_table['id'],\n",
    "        delimiter =\", \",\n",
    "        fmt ='% s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take the common ones among unequal variance and nonlinear (bcmi cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.05\n",
      "For variance cutoff 0\n",
      "Length of var causal dataset 1752\n",
      "Length of nonlinear causal dataset 63\n",
      "Length of causal dataset 63\n",
      "Length of independent dataset 63\n",
      "printing the diference ............. \n",
      "In list1 but not in list2: []\n",
      "{512, 384, 258, 1156, 1414, 1031, 136, 1033, 394, 908, 1038, 1168, 145, 1555, 1300, 1301, 1174, 1560, 1306, 1307, 539, 1437, 1312, 928, 1447, 1194, 1452, 941, 1711, 815, 1077, 1595, 1340, 444, 574, 447, 577, 1345, 1477, 72, 842, 846, 1231, 1360, 1491, 984, 986, 604, 1117, 863, 612, 484, 358, 1127, 1515, 108, 1645, 878, 753, 1523, 630, 1275, 1663}\n",
      "{512, 384, 258, 1156, 1414, 1031, 136, 1033, 394, 908, 1038, 1168, 145, 1555, 1300, 1301, 1174, 1560, 1306, 1307, 539, 1437, 1312, 928, 1447, 1194, 1452, 941, 1711, 815, 1077, 1595, 1340, 444, 574, 447, 577, 1345, 1477, 72, 842, 846, 1231, 1360, 1491, 984, 986, 604, 1117, 863, 612, 484, 358, 1127, 1515, 108, 1645, 878, 753, 1523, 630, 1275, 1663}\n",
      "variance cutoff  0 bcmi both cutoff  0.05 random classifier  0.5\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.1\n",
      "For variance cutoff 0\n",
      "Length of var causal dataset 1752\n",
      "Length of nonlinear causal dataset 15\n",
      "Length of causal dataset 15\n",
      "Length of independent dataset 15\n",
      "variance cutoff  0 bcmi both cutoff  0.1 random classifier  0.5\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.15\n",
      "For variance cutoff 0\n",
      "Length of var causal dataset 1752\n",
      "Length of nonlinear causal dataset 11\n",
      "Length of causal dataset 11\n",
      "Length of independent dataset 11\n",
      "variance cutoff  0 bcmi both cutoff  0.15 random classifier  0.5\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.05\n",
      "For variance cutoff 0.05\n",
      "Length of var causal dataset 1465\n",
      "Length of nonlinear causal dataset 63\n",
      "Length of causal dataset 54\n",
      "Length of independent dataset 49\n",
      "variance cutoff  0.05 bcmi both cutoff  0.05 random classifier  0.5242718446601942\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.1\n",
      "For variance cutoff 0.05\n",
      "Length of var causal dataset 1465\n",
      "Length of nonlinear causal dataset 15\n",
      "Length of causal dataset 8\n",
      "Length of independent dataset 11\n",
      "variance cutoff  0.05 bcmi both cutoff  0.1 random classifier  0.42105263157894735\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.15\n",
      "For variance cutoff 0.05\n",
      "Length of var causal dataset 1465\n",
      "Length of nonlinear causal dataset 11\n",
      "Length of causal dataset 5\n",
      "Length of independent dataset 9\n",
      "variance cutoff  0.05 bcmi both cutoff  0.15 random classifier  0.35714285714285715\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.05\n",
      "For variance cutoff 0.1\n",
      "Length of var causal dataset 1401\n",
      "Length of nonlinear causal dataset 63\n",
      "Length of causal dataset 54\n",
      "Length of independent dataset 46\n",
      "variance cutoff  0.1 bcmi both cutoff  0.05 random classifier  0.54\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.1\n",
      "For variance cutoff 0.1\n",
      "Length of var causal dataset 1401\n",
      "Length of nonlinear causal dataset 15\n",
      "Length of causal dataset 8\n",
      "Length of independent dataset 11\n",
      "variance cutoff  0.1 bcmi both cutoff  0.1 random classifier  0.42105263157894735\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.15\n",
      "For variance cutoff 0.1\n",
      "Length of var causal dataset 1401\n",
      "Length of nonlinear causal dataset 11\n",
      "Length of causal dataset 5\n",
      "Length of independent dataset 9\n",
      "variance cutoff  0.1 bcmi both cutoff  0.15 random classifier  0.35714285714285715\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.05\n",
      "For variance cutoff 0.125\n",
      "Length of var causal dataset 1356\n",
      "Length of nonlinear causal dataset 63\n",
      "Length of causal dataset 53\n",
      "Length of independent dataset 46\n",
      "variance cutoff  0.125 bcmi both cutoff  0.05 random classifier  0.5353535353535354\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.1\n",
      "For variance cutoff 0.125\n",
      "Length of var causal dataset 1356\n",
      "Length of nonlinear causal dataset 15\n",
      "Length of causal dataset 8\n",
      "Length of independent dataset 9\n",
      "variance cutoff  0.125 bcmi both cutoff  0.1 random classifier  0.47058823529411764\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.15\n",
      "For variance cutoff 0.125\n",
      "Length of var causal dataset 1356\n",
      "Length of nonlinear causal dataset 11\n",
      "Length of causal dataset 5\n",
      "Length of independent dataset 9\n",
      "variance cutoff  0.125 bcmi both cutoff  0.15 random classifier  0.35714285714285715\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.05\n",
      "For variance cutoff 0.15\n",
      "Length of var causal dataset 623\n",
      "Length of nonlinear causal dataset 63\n",
      "Length of causal dataset 12\n",
      "Length of independent dataset 16\n",
      "variance cutoff  0.15 bcmi both cutoff  0.05 random classifier  0.42857142857142855\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.1\n",
      "For variance cutoff 0.15\n",
      "Length of var causal dataset 623\n",
      "Length of nonlinear causal dataset 15\n",
      "Length of causal dataset 4\n",
      "Length of independent dataset 4\n",
      "variance cutoff  0.15 bcmi both cutoff  0.1 random classifier  0.5\n",
      "For ODC cutoff 0.05\n",
      "For BCMI cutoff 0.15\n",
      "For variance cutoff 0.15\n",
      "Length of var causal dataset 623\n",
      "Length of nonlinear causal dataset 11\n",
      "Length of causal dataset 3\n",
      "Length of independent dataset 4\n",
      "variance cutoff  0.15 bcmi both cutoff  0.15 random classifier  0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "#var_cutoff=[0,0.1,0.125,0.15,0.175,0.2,0.225,0.25]\n",
    "var_cutoff=[0,0.05,0.1,0.125,0.15]\n",
    "bcmi_cutoff=[0.05,0.1,0.15]\n",
    "odc_cutoff=[0.05]\n",
    "seed_number=10 # change the seed here from 1 to 10\n",
    "os.chdir('/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts')\n",
    "cutoff_type='bcmi'\n",
    "directory = \"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/varandnonlinear_indices/seed\" + str(seed_number)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for i in var_cutoff:\n",
    "    for j in bcmi_cutoff:\n",
    "        for k in odc_cutoff:\n",
    "            print(\"For ODC cutoff\", k)\n",
    "            print(\"For BCMI cutoff\", j)\n",
    "            print(\"For variance cutoff\", i)\n",
    "            # var causal and inpendent are the same because only the cis genes matter here \n",
    "            var_causal_list=pd.read_csv(\"./var_indices/yeast_wilko_var_causal_\"+str(i)+\".csv\",header=None)[0].values.tolist()\n",
    "            nonlinear_causal_list=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/mpmi_indices/seed\"+str(seed_number)+ \"/yeast_wilko_mi_causal_\"+cutoff_type+str(j)+\"_\"+str(k)+\".csv\",header=None)[0].values.tolist()\n",
    "            nonlinear_indep_list=pd.read_csv(\"/data/users/cs20s037/CITNonLinear/findr/findrfiles/scripts/mpmi_indices/seed\"+str(seed_number)+\"/yeast_wilko_mi_indep_\"+cutoff_type+str(j)+\"_\"+str(k)+\".csv\",header=None)[0].values.tolist()\n",
    "            \n",
    "            common_causal_len=len(set(var_causal_list).intersection(set(nonlinear_causal_list))) \n",
    "            common_indep_len=len(set(var_causal_list).intersection(set(nonlinear_indep_list))) \n",
    "            print('Length of var causal dataset',len(var_causal_list))\n",
    "            print('Length of nonlinear causal dataset',len(nonlinear_causal_list))\n",
    "            print('Length of causal dataset',common_causal_len)\n",
    "            print('Length of independent dataset',common_indep_len)\n",
    "\n",
    "\n",
    "            common_causal_list=list(set(var_causal_list).intersection(set(nonlinear_causal_list)))\n",
    "            common_indep_list=list(set(var_causal_list).intersection(set(nonlinear_indep_list)))\n",
    "            random_classifier=common_causal_len/(common_causal_len+common_indep_len)\n",
    "\n",
    "            # if i==0 and j==0.05:\n",
    "            #     print(\"printing the diference ............. \")\n",
    "            #     #print(nonlinear_causal_list)\n",
    "            #     diff1 = list(set(nonlinear_causal_list) - set(common_causal_list))\n",
    "            #     print(\"In list1 but not in list2:\", diff1)\n",
    "            #     print(set(nonlinear_indep_list))\n",
    "            #     print(set(common_indep_list))\n",
    "\n",
    "\n",
    "            print(\"variance cutoff \",i,\"bcmi both cutoff \",j,\"random classifier \",random_classifier )\n",
    "                    # Write to file only if the path doesn't exist\n",
    "            output_file_path = directory + \"/yeast_causal_var\" + str(i) + cutoff_type + str(j)+\"_\"+str(k)+\".csv\"\n",
    "            if not os.path.exists(output_file_path):\n",
    "                np.savetxt(output_file_path,common_causal_list , delimiter=\",\", fmt='% s')\n",
    "            \n",
    "            output_file_path = directory + \"/yeast_indep_var\" + str(i) + cutoff_type + str(j)+\"_\"+str(k)+\".csv\"\n",
    "            if not os.path.exists(output_file_path):\n",
    "                np.savetxt(output_file_path, common_indep_list, delimiter=\",\", fmt='% s')\n",
    "\n",
    "            output_file_path = directory + \"/yeast_other_var\" + str(i) + cutoff_type + str(j)+\"_\"+str(k)+\".csv\"\n",
    "            if not os.path.exists(output_file_path):\n",
    "                np.savetxt(output_file_path, [common_causal_len,common_indep_len,random_classifier], delimiter=\",\", fmt='% s')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
