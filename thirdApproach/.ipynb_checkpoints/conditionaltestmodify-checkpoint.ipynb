{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qd6CiVe-jyEn",
    "outputId": "b4187c26-21ff-4edc-e194-db58fd55f233"
   },
   "outputs": [],
   "source": [
    "#loading the libraries\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Concatenate\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from scipy import stats\n",
    "import rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "OxvAXLLFnl7d"
   },
   "outputs": [],
   "source": [
    "#defining the class MDN\n",
    "class MDN_module(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, neurons=15, components = 1):\n",
    "        super(MDN_module, self).__init__(name=\"MDN_module\")\n",
    "        self.neurons = neurons\n",
    "        self.components = components\n",
    "\n",
    "        #chaging activation to relu from linear, changin relu to sigmoid \n",
    "        for i in range(1,3):\n",
    "          s=\"self\"+\".h\"+str(i)+\"= Dense(neurons, activation=\\\"relu\\\", name=\"+\"'h\"+str(i)+\"')\"\n",
    "          exec(s)\n",
    "        self.alphas = Dense(components, activation=\"softmax\", name=\"alphas\")\n",
    "        self.mus = Dense(components, activation=\"linear\",name=\"mus\") \n",
    "        self.sigmas = Dense(components, activation=\"nnelu\",name=\"sigmas\") #activation changed from linear to default\n",
    "        self.pvec = Concatenate(name=\"pvec\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x=self.h1(inputs)\n",
    "        #x=self.inputA(inputs)\n",
    "        x=self.h2(x)\n",
    "        alpha_v = self.alphas(x)\n",
    "        mu_v = self.mus(x)\n",
    "        sigma_v = self.sigmas(x)\n",
    "        \n",
    "        return self.pvec([alpha_v,mu_v, sigma_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "7DSPXmR1ogiH"
   },
   "outputs": [],
   "source": [
    "no_parameters=3\n",
    "components=1\n",
    "def nnelu(input):\n",
    "    \"\"\" Computes the Non-Negative Exponential Linear Unit\n",
    "    \"\"\"\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def slice_parameter_vectors(parameter_vector):\n",
    "    \"\"\" Returns an unpacked list of paramter vectors.\n",
    "    \"\"\"\n",
    "    return [parameter_vector[:,i*components:(i+1\n",
    "    )*components] for i in range(no_parameters)]\n",
    "\n",
    "def gnll_loss(y, parameter_vector):\n",
    "    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n",
    "    \"\"\"\n",
    "    alpha,mu,sigma = slice_parameter_vectors(parameter_vector) # Unpack parameter vectors\n",
    "    #tf.print(sigma)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "           mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "           components_distribution=tfd.Normal(\n",
    "           loc=mu,       \n",
    "           scale=sigma))\n",
    "    \n",
    "    \n",
    "    \n",
    "    log_likelihood =  gm.log_prob(tf.transpose(y)) # Evaluate log-probability of y \n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1) \n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': Activation(nnelu)})\n",
    "\n",
    "def gnll_eval(y,alpha, mu, sigma):\n",
    "    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n",
    "    \"\"\"\n",
    "    #print(alpha)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,       \n",
    "            scale=sigma))\n",
    "    log_likelihood = gm.log_prob(tf.transpose(y))\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "\n",
    "def eval_mdn_model(x_test, y_test, mdn_model):\n",
    "    \"\"\" Evaluate the model to get the loss for the given x and y \n",
    "    \"\"\"\n",
    "    y_pred = mdn_model.predict(np.reshape(x_test,newshape=(len(x_test),-1)))\n",
    "    alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "    mdn_nll = gnll_eval(y_test.astype(np.float32),alpha, mu, sigma).numpy()\n",
    "    return mdn_nll\n",
    "#reshapefunction\n",
    "def eval_mdn_model_mle(x_test,y_test):\n",
    "        indices_1 = [i for i, x in enumerate(x_test) if x == 1]\n",
    "        indices_0 = [i for i, x in enumerate(x_test) if x == 0]\n",
    "        mu_0=np.mean(y_test[indices_0])\n",
    "        mu_1=np.mean(y_test[indices_1])\n",
    "        sigma_0=np.std(y_test[indices_0])\n",
    "        sigma_1=np.std(y_test[indices_1])\n",
    "        y_mean=np.zeros((len(y_test),1))\n",
    "        y_mean[indices_1]=mu_1\n",
    "        y_mean[indices_0]=mu_0\n",
    "        y_std=np.zeros((len(y_test),1))\n",
    "        y_std[indices_1]=sigma_1\n",
    "        y_std[indices_0]=sigma_0\n",
    "        alpha=np.ones((len(y_mean),1))\n",
    "        return gnll_eval(y_test,alpha,y_mean,y_std).numpy()\n",
    "    \n",
    "def reshapevar(X):\n",
    "  \"\"\"\n",
    "  Function to reshape the vector for the input \n",
    "  \"\"\"\n",
    "  return np.reshape(X,newshape=(len(X),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T6sJ7ffirsnB"
   },
   "outputs": [],
   "source": [
    "def compute_loss(P,Q,mle=False):\n",
    "    \"\"\" Compute the loss for the given pair\n",
    "    \"\"\"\n",
    "    if(mle==False):\n",
    "        opt = tf.optimizers.Adam(1e-2)\n",
    "        mdn_PQ = MDN_module()\n",
    "        mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "        mdn_PQ.fit(x=reshapevar(P), y=np.array(Q).T,epochs=100,  batch_size=64,verbose=0)\n",
    "        #return np.array(nlcor.nlcor(P,Q)[0])[0]\n",
    "        return eval_mdn_model(P,Q,mdn_PQ)\n",
    "    else:\n",
    "        return eval_mdn_model_mle(P,Q)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_y_pred(P,Q,mle=False):\n",
    "    \"\"\" Compute the loss for the given pair\n",
    "    \"\"\"\n",
    "    if(mle==False):\n",
    "        opt = tf.optimizers.Adam(1e-2)\n",
    "        mdn_PQ = MDN_module()\n",
    "        mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "        mdn_PQ.fit(x=reshapevar(P), y=np.array(Q).T,epochs=100,  batch_size=64,verbose=0)\n",
    "        y_pred = mdn_PQ.predict(np.reshape(P,newshape=(len(P),-1)))\n",
    "        return y_pred[:,1]\n",
    "    else:\n",
    "        indices_1 = [i for i, x in enumerate(P) if x == 1]\n",
    "        indices_0 = [i for i, x in enumerate(P) if x == 0]\n",
    "        mu_0=np.mean(Q[indices_0])\n",
    "        mu_1=np.mean(Q[indices_1])\n",
    "        #sigma_0=np.std(Q[indices_0])\n",
    "        #sigma_1=np.std(Q[indices_1])\n",
    "        y_mean=np.zeros((len(Q),1))\n",
    "        y_mean[indices_1]=mu_1\n",
    "        y_mean[indices_0]=mu_0\n",
    "        return y_mean.reshape((len(y_mean),))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X6V8X2QFpmC7"
   },
   "outputs": [],
   "source": [
    "def shuffleBtimes(P,Q,B,mle=False):\n",
    "    \"\"\" Shuffle Q B times and compute the loss \n",
    "    \"\"\"\n",
    "    loss=[]\n",
    "    if(mle==False):\n",
    "        for i in range(0,B):\n",
    "          loss.append(compute_loss(P,np.random.permutation(Q)))\n",
    "    else:\n",
    "        for i in range(0,B):\n",
    "          loss.append(compute_loss(P,np.random.permutation(Q),True))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iUW3ikOHu6PO"
   },
   "outputs": [],
   "source": [
    "def LinearLABData():\n",
    "    \"\"\" Generate the linear data \n",
    "    \"\"\"\n",
    "    L = np.random.binomial(1,0.5,1000)  \n",
    "    beta0 = np.ones(1000)-0.4\n",
    "    #beta1 = 0.5\n",
    "    beta1=3\n",
    "    beta2= 0.3\n",
    "    beta3=0.8\n",
    "    #eps0 = np.random.standard_normal(1000)\n",
    "    #eps1 = np.random.standard_normal(1000)\n",
    "    eps0 = np.random.normal(0,1,1000)\n",
    "    eps1 = np.random.normal(0,1,1000)\n",
    "    A = beta0 + beta1*L + eps0\n",
    "    #B=beta2+beta3*np.sin(A)+eps1\n",
    "    B = beta2+ beta3*A + eps1 \n",
    "    plt.scatter(A,B)\n",
    "    plt.title(\"A vs B\")\n",
    "    plt.xlabel(\"A\")\n",
    "    plt.ylabel(\"B\")\n",
    "    return [L,A,B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.418004, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#def conditional_independence():\n",
    "opt = tf.optimizers.Adam(1e-2)\n",
    "mdn_PQ = MDN_module()\n",
    "mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "##changing epochs didnt make much difference\n",
    "\n",
    "#mdn_PQ.fit(x=C, y=np.array(B).T,epochs=300,  batch_size=64)\n",
    "withoutL=mdn_PQ.fit(x=reshapevar(A), y=np.array(B).T,epochs=100,  batch_size=64,verbose=0)\n",
    "y_pred = mdn_PQ.predict(reshapevar(A))\n",
    "alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,       \n",
    "            scale=sigma))\n",
    "log_likelihood = gm.log_prob(np.array(B)).numpy()\n",
    "print(-tf.reduce_mean(log_likelihood, axis=-1))\n",
    "\n",
    "    #y_pred = mdn_PQ.predict(np.reshape(P,newshape=(len(P),-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4375391006469727"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withoutL.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 873us/step - loss: 3.0172\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 897us/step - loss: 1.9222\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 822us/step - loss: 1.6232\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4597\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 925us/step - loss: 1.4398\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 915us/step - loss: 1.4353\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 967us/step - loss: 1.4347\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4239\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4287\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4285\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4166\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4251\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4252\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4272\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4224\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4227\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4181\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4369\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4293\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4144\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4196\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4206\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4204\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4152\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4642\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4203\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4227\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4152\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4235\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4142\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4216\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4117\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4243\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4251\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4138\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4175\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4193\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4175\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4212\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4133\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4133\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4161\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4169\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4105\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4168\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4123\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4218\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4244\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4172\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4139\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4209\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4279\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4202\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 975us/step - loss: 1.4111\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4156\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 982us/step - loss: 1.4172\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4121\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4155\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4157\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 972us/step - loss: 1.4180\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 962us/step - loss: 1.4133\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 973us/step - loss: 1.4134\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 985us/step - loss: 1.4114\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 958us/step - loss: 1.4209\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 944us/step - loss: 1.4195\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4238\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 957us/step - loss: 1.4176\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 954us/step - loss: 1.4089\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4252\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 957us/step - loss: 1.4176\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 989us/step - loss: 1.4240\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4214\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4215\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4136\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 982us/step - loss: 1.4151\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 965us/step - loss: 1.4201\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 940us/step - loss: 1.4259\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4329\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4432\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 912us/step - loss: 1.4226\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 924us/step - loss: 1.4217\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 911us/step - loss: 1.4168\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 928us/step - loss: 1.4152\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 977us/step - loss: 1.4190\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 942us/step - loss: 1.4199\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 897us/step - loss: 1.4173\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 930us/step - loss: 1.4104\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 918us/step - loss: 1.4131\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 877us/step - loss: 1.4108\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 865us/step - loss: 1.4165\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 938us/step - loss: 1.4126\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 969us/step - loss: 1.4109\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 961us/step - loss: 1.4137\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 908us/step - loss: 1.4147\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 921us/step - loss: 1.4110\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 995us/step - loss: 1.4140\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4130\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 978us/step - loss: 1.4185\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4116\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4091\n",
      "tf.Tensor(1.4125937, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "opt = tf.optimizers.Adam(1e-2)\n",
    "mdn_PQ = MDN_module()\n",
    "mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "##changing epochs didnt make much difference\n",
    "withL=mdn_PQ.fit(x=C, y=np.array(B).T,epochs=100,  batch_size=64,verbose=0)\n",
    "#history2=mdn_PQ.fit(x=reshapevar(A), y=np.array(B).T,epochs=300,  batch_size=64)\n",
    "y_pred = mdn_PQ.predict(C)\n",
    "alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,       \n",
    "            scale=sigma))\n",
    "log_likelihood = gm.log_prob(np.array(B)).numpy()\n",
    "print(-tf.reduce_mean(log_likelihood, axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7326240539550781"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withoutL.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6749807596206665"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withL.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_mod=L.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mod=A.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=np.concatenate([L_mod,A_mod],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast_name=\"\"\n",
    "def yeast_data(i,ind):\n",
    "    '''\n",
    "    Function to return the trios with the gndtruth 0/1 based on i and the number based on ind \n",
    "    '''\n",
    "    global yeast_name\n",
    "    yeast_name=\"yeast_\"+str(i)+\"_\"+str(ind)\n",
    "    ds = eval(\"dataset_\"+str(i)+\"[\"+str(ind)+\"]\")\n",
    "    L_dist = np.array(ds[0]) #np.array(ds[0])\n",
    "    A_dist = np.array(ds[1])\n",
    "    B_dist = np.array(ds[2])\n",
    "    plt.scatter(A_dist,B_dist)\n",
    "    plt.title(\"A vs B\")\n",
    "    plt.xlabel(\"A\")\n",
    "    plt.ylabel(\"B\")\n",
    "    return [L_dist,A_dist,B_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pvalue(original,loss_list):\n",
    "    '''\n",
    "    calculate the p value \n",
    "    '''\n",
    "    return sum(i < original for i in loss_list)/len(loss_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_B_n_times(L,A,B,n,mle=False):\n",
    "    '''\n",
    "    Stratify B wrt to L\n",
    "    '''\n",
    "    loss=[]\n",
    "    indices_1 = [i for i, x in enumerate(L) if x == 1]\n",
    "    indices_0 = [i for i, x in enumerate(L) if x == 0]\n",
    "    for i in range(0,n):\n",
    "\n",
    "        B_dist_temp=np.zeros(len(B))\n",
    "        mod_indices_1=random.sample(indices_1,len(indices_1))\n",
    "        for i in range(len(indices_1)):\n",
    "            B_dist_temp[indices_1[i]]=B[mod_indices_1[i]]\n",
    "\n",
    "        mod_indices_0=random.sample(indices_0,len(indices_0))\n",
    "        for i in range(len(indices_0)):\n",
    "            B_dist_temp[indices_0[i]]=B[mod_indices_0[i]]\n",
    "        #print(B_dist_temp)\n",
    "        if(mle==False):\n",
    "            loss.append(compute_loss(L,residual(A,B_dist_temp)))\n",
    "        else:\n",
    "            loss.append(compute_loss(L,residual(A,B_dist_temp),True))\n",
    "\n",
    "    return loss \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_third_testloss(A,B):\n",
    "    opt = tf.optimizers.Adam(1e-2)\n",
    "    mdn_PQ = MDN_module()\n",
    "    mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "##changing epochs didnt make much difference\n",
    "\n",
    "#mdn_PQ.fit(x=C, y=np.array(B).T,epochs=300,  batch_size=64)\n",
    "    withoutL=mdn_PQ.fit(x=A, y=B.T,epochs=100,  batch_size=64,verbose=0)\n",
    "    y_pred = mdn_PQ.predict(A)\n",
    "    alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,       \n",
    "            scale=sigma))\n",
    "    log_likelihood = gm.log_prob(B).numpy()\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difference(L,A,B):\n",
    "    return compute_third_testloss(reshapevar(A),np.array(B))-compute_third_testloss(np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1),np.array(B))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_B_n_times_diff(L,A,B,n):\n",
    "    loss=[]\n",
    "    indices_1 = [i for i, x in enumerate(L) if x == 1]\n",
    "    indices_0 = [i for i, x in enumerate(L) if x == 0]\n",
    "    for i in range(0,n):\n",
    "        B_dist_temp=np.zeros(len(B))\n",
    "        mod_indices_1=random.sample(indices_1,len(indices_1))\n",
    "        for i in range(len(indices_1)):\n",
    "            B_dist_temp[indices_1[i]]=B[mod_indices_1[i]]\n",
    "\n",
    "        mod_indices_0=random.sample(indices_0,len(indices_0))\n",
    "        for i in range(len(indices_0)):\n",
    "            B_dist_temp[indices_0[i]]=B[mod_indices_0[i]]\n",
    "        loss.append(calculate_difference(L,A,B_dist_temp))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030863285"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(compute_third_testloss(reshapevar(A),np.array(B)))\n",
    "#print(compute_third_testloss(np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1),np.array(B)))\n",
    "calculate_difference(L,A,B)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "8NWufrxKokcX",
    "outputId": "b8f25bde-64db-4b27-86fb-05f7a5cf39cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffles=10\n",
    "L,A,B=LinearLABData()\n",
    "#L,A,B=yeast_data(1,444)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "A_shuffle=np.copy(A)\n",
    "B_shuffle=np.copy(B)\n",
    "#print(\"Original\",B_shuffle)\n",
    "loss_list_LA=shuffleBtimes(L,A_shuffle,shuffles,True)\n",
    "loss_list_LB=shuffleBtimes(L,B_shuffle,shuffles,True)\n",
    "loss_list_third=stratify_B_n_times_diff(L,A_shuffle,B_shuffle,shuffles) #conditional independence test\n",
    "true_LA=compute_loss(L,A,True)\n",
    "true_LB=compute_loss(L,B,True)\n",
    "#print(\"Next\",B_shuffle)\n",
    "true_loss_third=calculate_difference(L,A,B)\n",
    "print(calculate_pvalue(true_LA,loss_list_LA))\n",
    "print(calculate_pvalue(true_LB,loss_list_LB))\n",
    "print(calculate_pvalue(true_loss_third,loss_list_third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6985755829609235,\n",
       " 1.6997718774561918,\n",
       " 1.6731068788334529,\n",
       " 1.7067214226757852,\n",
       " 1.6985168033472264,\n",
       " 1.7012444635871748,\n",
       " 1.6740837903396604,\n",
       " 1.6920716605588682,\n",
       " 1.6777053468812924,\n",
       " 1.6658451078304697]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking whether the losses given using deep network and mle are the same \n",
    "loss_list_Bresidual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zfCEe9r8DcW",
    "outputId": "d98f4675-d52a-4717-adf3-c2aabbb436ba"
   },
   "outputs": [],
   "source": [
    "pickle_items=[loss_list_LA,loss_list_LB,loss_list_LindB_A,true_LA,true_LB,true_LindB_A]\n",
    "file_name=str(shuffles)+\"shuffles\"+yeast_name+\".pkl\"\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(pickle_items, open_file)\n",
    "open_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1SaPyLVQ8QT7",
    "outputId": "921fe364-62d6-4c2d-a6be-0c9e8e60a74c"
   },
   "outputs": [],
   "source": [
    "file_name=\"100shufflesyeast_1_444.pkl\"\n",
    "open_file = open(file_name, \"rb\")\n",
    "\n",
    "loaded_list = pickle.load(open_file)\n",
    "\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_LA,loss_list_LB,loss_list_LindB_A,true_LA,true_LB,true_LindB_A=loaded_list"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CITNonLinear.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
