{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qd6CiVe-jyEn",
    "outputId": "b4187c26-21ff-4edc-e194-db58fd55f233"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:13:23.883569: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-23 16:13:23.883594: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#loading the libraries\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Concatenate\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from scipy import stats\n",
    "import rpy2\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "from CCIT import CCIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OxvAXLLFnl7d"
   },
   "outputs": [],
   "source": [
    "#defining the class MDN\n",
    "class MDN_module(tf.keras.Model):\n",
    "#changed from 15 to 20\n",
    "    def __init__(self, neurons=15, components = 1):\n",
    "        super(MDN_module, self).__init__(name=\"MDN_module\")\n",
    "        self.neurons = neurons\n",
    "        self.components = components\n",
    "\n",
    "        #chaging activation to relu from linear, changin relu to sigmoid \n",
    "        for i in range(1,3):\n",
    "          s=\"self\"+\".h\"+str(i)+\"= Dense(neurons, activation=\\\"relu\\\", name=\"+\"'h\"+str(i)+\"')\"\n",
    "          exec(s)\n",
    "        #self.h1=Dense(12,activation=\"relu\",name=\"h1\")\n",
    "        #self.h2=Dense(8,activation=\"relu\",name=\"h2\")\n",
    "        #self.h3=Dense(8,activation=\"relu\",name=\"h3\")\n",
    "        self.alphas = Dense(components, activation=\"softmax\", name=\"alphas\")\n",
    "        self.mus = Dense(components, activation=\"linear\",name=\"mus\") \n",
    "        self.sigmas = Dense(components, activation=\"nnelu\",name=\"sigmas\") #activation changed from linear to default\n",
    "        self.pvec = Concatenate(name=\"pvec\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x=self.h1(inputs)\n",
    "        #x=self.inputA(inputs)\n",
    "        x=self.h2(x)\n",
    "        #x=self.h3(x)\n",
    "        alpha_v = self.alphas(x)\n",
    "        mu_v = self.mus(x)\n",
    "        sigma_v = self.sigmas(x)\n",
    "        \n",
    "        return self.pvec([alpha_v,mu_v, sigma_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7DSPXmR1ogiH"
   },
   "outputs": [],
   "source": [
    "no_parameters=3\n",
    "components=1\n",
    "def nnelu(input):\n",
    "    \"\"\" Computes the Non-Negative Exponential Linear Unit\n",
    "    \"\"\"\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def slice_parameter_vectors(parameter_vector):\n",
    "    \"\"\" Returns an unpacked list of paramter vectors.\n",
    "    \"\"\"\n",
    "    return [parameter_vector[:,i*components:(i+1\n",
    "    )*components] for i in range(no_parameters)]\n",
    "\n",
    "def gnll_loss(y, parameter_vector):\n",
    "    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n",
    "    \"\"\"\n",
    "    alpha,mu,sigma = slice_parameter_vectors(parameter_vector) # Unpack parameter vectors\n",
    "    #tf.print(sigma)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "           mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "           components_distribution=tfd.Normal(\n",
    "           loc=mu,       \n",
    "           scale=sigma))\n",
    "    \n",
    "    \n",
    "    \n",
    "    log_likelihood =  gm.log_prob(tf.transpose(y)) # Evaluate log-probability of y \n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1) \n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': Activation(nnelu)})\n",
    "\n",
    "def gnll_eval(y,alpha, mu, sigma):\n",
    "    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n",
    "    \"\"\"\n",
    "    #print(alpha)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,       \n",
    "            scale=sigma))\n",
    "    log_likelihood = gm.log_prob(tf.transpose(y))\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "\n",
    "def eval_mdn_model(x_test, y_test, mdn_model):\n",
    "    \"\"\" Evaluate the model to get the loss for the given x and y \n",
    "    \"\"\"\n",
    "    y_pred = mdn_model.predict(np.reshape(x_test,newshape=(len(x_test),-1)))\n",
    "    alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "    mdn_nll = gnll_eval(y_test.astype(np.float32),alpha, mu, sigma).numpy()\n",
    "    return mdn_nll\n",
    "#reshapefunction\n",
    "def eval_mdn_model_mle(x_test,y_test):\n",
    "        indices_1 = [i for i, x in enumerate(x_test) if x == 1]\n",
    "        #changing x to -1\n",
    "        indices_0 = [i for i, x in enumerate(x_test) if x == 0]\n",
    "        mu_0=np.mean(y_test[indices_0])\n",
    "        mu_1=np.mean(y_test[indices_1])\n",
    "        sigma_0=np.std(y_test[indices_0])\n",
    "        sigma_1=np.std(y_test[indices_1])\n",
    "        y_mean=np.zeros((len(y_test),1))\n",
    "        y_mean[indices_1]=mu_1\n",
    "        y_mean[indices_0]=mu_0\n",
    "        y_std=np.zeros((len(y_test),1))\n",
    "        y_std[indices_1]=sigma_1\n",
    "        y_std[indices_0]=sigma_0\n",
    "        alpha=np.ones((len(y_mean),1))\n",
    "        return gnll_eval(y_test,alpha,y_mean,y_std).numpy()\n",
    "    \n",
    "def reshapevar(X):\n",
    "  \"\"\"\n",
    "  Function to reshape the vector for the input \n",
    "  \"\"\"\n",
    "  return np.reshape(X,newshape=(len(X),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T6sJ7ffirsnB"
   },
   "outputs": [],
   "source": [
    "def compute_loss(P,Q,mle=False):\n",
    "    \"\"\" Compute the loss for the given pair\n",
    "    \"\"\"\n",
    "    if(mle==False):\n",
    "        opt = tf.optimizers.Adam(1e-2)\n",
    "        mdn_PQ = MDN_module()\n",
    "        mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "        mdn_PQ.fit(x=reshapevar(P), y=np.array(Q).T,epochs=100,  batch_size=64,verbose=0)\n",
    "        #return np.array(nlcor.nlcor(P,Q)[0])[0]\n",
    "        return eval_mdn_model(P,Q,mdn_PQ)\n",
    "    else:\n",
    "        return eval_mdn_model_mle(P,Q)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_y_pred(P,Q,mle=False):\n",
    "    \"\"\" Compute the loss for the given pair\n",
    "    \"\"\"\n",
    "    if(mle==False):\n",
    "        opt = tf.optimizers.Adam(1e-2)\n",
    "        mdn_PQ = MDN_module()\n",
    "        mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "        mdn_PQ.fit(x=reshapevar(P), y=np.array(Q).T,epochs=100,  batch_size=64,verbose=0)\n",
    "        y_pred = mdn_PQ.predict(np.reshape(P,newshape=(len(P),-1)))\n",
    "        return y_pred[:,1]\n",
    "    else:\n",
    "        indices_1 = [i for i, x in enumerate(P) if x == 1]\n",
    "        indices_0 = [i for i, x in enumerate(P) if x == 0]\n",
    "        mu_0=np.mean(Q[indices_0])\n",
    "        mu_1=np.mean(Q[indices_1])\n",
    "        #sigma_0=np.std(Q[indices_0])\n",
    "        #sigma_1=np.std(Q[indices_1])\n",
    "        y_mean=np.zeros((len(Q),1))\n",
    "        y_mean[indices_1]=mu_1\n",
    "        y_mean[indices_0]=mu_0\n",
    "        return y_mean.reshape((len(y_mean),))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X6V8X2QFpmC7"
   },
   "outputs": [],
   "source": [
    "def shuffleBtimes(P,Q,B,mle=False):\n",
    "    \"\"\" Shuffle Q B times and compute the loss \n",
    "    \"\"\"\n",
    "    loss=[]\n",
    "    if(mle==False):\n",
    "        for i in range(0,B):\n",
    "          loss.append(compute_loss(P,np.random.permutation(Q)))\n",
    "    else:\n",
    "        for i in range(0,B):\n",
    "          loss.append(compute_loss(P,np.random.permutation(Q),True))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iUW3ikOHu6PO"
   },
   "outputs": [],
   "source": [
    "def LinearLABData():\n",
    "    \"\"\" Generate the linear data \n",
    "    \"\"\"\n",
    "    L = np.random.binomial(1,0.5,1000)  \n",
    "    beta0 = np.ones(1000)-0.4\n",
    "    #beta1 = 0.5\n",
    "    beta1=3\n",
    "    beta2= 0.3\n",
    "    beta3=0.8\n",
    "    #eps0 = np.random.standard_normal(1000)\n",
    "    #eps1 = np.random.standard_normal(1000)\n",
    "    eps0 = np.random.normal(0,1,1000)\n",
    "    eps1 = np.random.normal(0,1,1000)\n",
    "    A = beta0 + beta1*L + eps0\n",
    "    #B=beta2+beta3*np.sin(A)+eps1\n",
    "    B = beta2+ beta3*A + eps1 \n",
    "    plt.scatter(A,B)\n",
    "    plt.title(\"A vs B\")\n",
    "    plt.xlabel(\"A\")\n",
    "    plt.ylabel(\"B\")\n",
    "    return [L,A,B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo=open(\"/home/aravind/projects/CIT_Non_Linear/LinearDifferentvalues/testing_writingvalues_Linear0to1.txt\", \"r\")\n",
    "L=[]\n",
    "A=[]\n",
    "B=[]\n",
    "#fe=open(\"dataset_params.txt\",'w')\n",
    "for i in range(0,121):\n",
    "    line=fo.readline()\n",
    "    #fe.write(line)\n",
    "    #line=line[1:-2] #remove double quotes \n",
    "    #param = [j for j in line.split()]\n",
    "    #print(param)\n",
    "    #chrname.append(param[1])\n",
    "    #g1.append(param[2])\n",
    "    #g2.append(param[3])\n",
    "    line=fo.readline()\n",
    "    l = [j for j in line.split()]\n",
    "    L.append([int(i) for i in l])\n",
    "    line=fo.readline()\n",
    "    a = [j for j in line.split()]\n",
    "    A.append([float(i) for i in a])\n",
    "    line=fo.readline()\n",
    "    b = [j for j in line.split()]\n",
    "    B.append([float(i) for i in b])\n",
    "dataset_linear = [i for i in zip(L,A,B)]\n",
    "fo.close()\n",
    "#fe.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pvalue(original,loss_list):\n",
    "    '''\n",
    "    calculate the p value \n",
    "    '''\n",
    "    return sum(i < original for i in loss_list)/len(loss_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_third_testloss(A,B):\n",
    "    opt = tf.optimizers.Adam(1e-2)\n",
    "    mdn_PQ = MDN_module()\n",
    "    mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "##changing epochs didnt make much difference\n",
    "\n",
    "#mdn_PQ.fit(x=C, y=np.array(B).T,epochs=300,  batch_size=64)\n",
    "    withoutL=mdn_PQ.fit(x=A, y=B.T,epochs=100,  batch_size=64,verbose=0)\n",
    "    y_pred = mdn_PQ.predict(A)\n",
    "    alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,       \n",
    "            scale=sigma))\n",
    "    log_likelihood = gm.log_prob(B).numpy()\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difference(L,A,B):\n",
    "    return compute_third_testloss(reshapevar(A),np.array(B))-compute_third_testloss(np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1),np.array(B))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_B_n_times_diff(L,A,B,n):\n",
    "    loss=[]\n",
    "    indices_1 = [i for i, x in enumerate(L) if x == 1]\n",
    "    #changing x== -1 \n",
    "    indices_0 = [i for i, x in enumerate(L) if x == 0]\n",
    "    for i in range(0,n):\n",
    "        B_dist_temp=np.zeros(len(B))\n",
    "        mod_indices_1=random.sample(indices_1,len(indices_1))\n",
    "        for i in range(len(indices_1)):\n",
    "            B_dist_temp[indices_1[i]]=B[mod_indices_1[i]]\n",
    "\n",
    "        mod_indices_0=random.sample(indices_0,len(indices_0))\n",
    "        for i in range(len(indices_0)):\n",
    "            B_dist_temp[indices_0[i]]=B[mod_indices_0[i]]\n",
    "        loss.append(calculate_difference(L,A,B_dist_temp))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=84\n",
    "A=np.array(dataset_linear[i][1])\n",
    "B=np.array(dataset_linear[i][2])\n",
    "L=np.array(dataset_linear[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [345]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m LB_p\u001b[38;5;241m=\u001b[39mcalculate_pvalue(true_LB,loss_list_LB)\n\u001b[1;32m     24\u001b[0m AB_p\u001b[38;5;241m=\u001b[39mcalculate_pvalue(true_LBresidual,loss_list_Bresidual)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLA_p\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLB_p\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAB_p\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "#for i in range(0,144):\n",
    "A=np.array(dataset_linear[i][1])\n",
    "B=np.array(dataset_linear[i][2])\n",
    "L=np.array(dataset_linear[i][0])\n",
    "shuffles=100\n",
    "A_shuffle=np.copy(A)\n",
    "B_shuffle=np.copy(B)\n",
    "#print(\"Original\",B_shufflep\n",
    "#changed the second test from mle to using neural networks\n",
    "loss_list_LA=shuffleBtimes(L,A_shuffle,shuffles,True)\n",
    "loss_list_LB=shuffleBtimes(L,B_shuffle,shuffles,True)\n",
    "#loss_list_Bresidual=stratify_B_n_times_diff(L,A_shuffle,B_shuffle,shuffles) #conditional independence test\n",
    "\n",
    "true_LA=compute_loss(L,A,True)\n",
    "true_LB=compute_loss(L,B,True)\n",
    "loss_list_Bresidual,true_LBresidual= calculateLshuffle(L,A,B,shuffles)\n",
    "#true_LBresidual=stratify_B_ntimes_permuteL(L,A,B,shuffles)\n",
    "#true_LBresidual=calculate_difference(L,A,B)\n",
    "#true_LBresidual=trueconditional(L,A,B)\n",
    "#loss_list_Bresidual=stratify_B_ntimes_permuteL(L,A_shuffle,B_shuffle,shuffles)\n",
    "#loss_list_Bresidual=stratify_B_ntimes_permuteL(L,A,B,shuffles,True)\n",
    "LA_p=calculate_pvalue(true_LA,loss_list_LA)\n",
    "LB_p=calculate_pvalue(true_LB,loss_list_LB)\n",
    "AB_p=calculate_pvalue(true_LBresidual,loss_list_Bresidual)\n",
    "f.write(str(i)+\",\"+str(LA_p)+\",\"+str(LB_p)+\",\"+str(AB_p)+\"\\n\")\n",
    "#AB_p=calculate_pvalue(true_LBresidual,loss_list_Bresidual)\n",
    "#mean_true=np.mean(true_LBresidual)\n",
    "#mean_shuffle=np.mean(loss_list_Bresidual)\n",
    "#std_true=np.std(true_LBresidual)\n",
    "#std_shuffle=np.std(loss_list_Bresidual)\n",
    "#f.write(str(i)+\",\"+str(LA_p)+\",\"+str(LB_p)+\",\"+str(mean_true)+\",\"+str(mean_shuffle)+\",\"+str(std_true)+\",\"+str(std_shuffle)+\"\\n\")\n",
    "#pickle_items=[loss_list_LA,loss_list_LB,loss_list_Bresidual,true_LA,true_LB,true_LBresidual,LA_p,LB_p,AB_p]\n",
    "#file_name=str(dataset_names[i])+\".pkl\"\n",
    "#open_file = open(\"./DLresultspickle/\"+file_name, \"wb\")\n",
    "#pickle.dump(pickle_items, open_file)\n",
    "#open_file.close()\n",
    "\n",
    "#if(mean_shuffle>mean_true):\n",
    "    #print(i)\n",
    "    #count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_p=calculate_pvalue(true_LA,loss_list_LA)\n",
    "LB_p=calculate_pvalue(true_LB,loss_list_LB)\n",
    "AB_p=calculate_pvalue(true_LBresidual,loss_list_Bresidual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the original LA->B and then shuffle L and calculate the loss, we are retraining the model \n",
    "#at every shuffle here\n",
    "def calculateLshuffle(L,A,B,shuffle):\n",
    "    loss_list=[]\n",
    "    opt = tf.optimizers.SGD(1e-3)\n",
    "    mdn_PQ = MDN_module()\n",
    "    mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "    withoutL=mdn_PQ.fit(x=np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1), y=B.T,epochs=100,  batch_size=32,verbose=0)\n",
    "    y_pred = mdn_PQ.predict(np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1))\n",
    "    alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "    mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "    components_distribution=tfd.Normal(\n",
    "    loc=mu,       \n",
    "    scale=sigma))\n",
    "    log_likelihood = gm.log_prob(B).numpy()\n",
    "    orig_loss= -tf.reduce_mean(log_likelihood, axis=-1).numpy()\n",
    "    for i in range(shuffle):\n",
    "        L_shuffle=np.random.permutation(L)\n",
    "        opt = tf.optimizers.SGD(1e-3)\n",
    "        mdn_PQ = MDN_module()\n",
    "        mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "        withoutL=mdn_PQ.fit(x=np.concatenate([L_shuffle.reshape(-1,1),A.reshape(-1,1)],axis=1), y=B.T,epochs=100,  batch_size=32,verbose=0)\n",
    "        y_pred = mdn_PQ.predict(np.concatenate([L_shuffle.reshape(-1,1),A.reshape(-1,1)],axis=1))\n",
    "        alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "        gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "        loc=mu,       \n",
    "        scale=sigma))\n",
    "        log_likelihood = gm.log_prob(B).numpy()\n",
    "        loss= -tf.reduce_mean(log_likelihood, axis=-1).numpy()\n",
    "        loss_list.append(loss)\n",
    "    \n",
    "    return loss_list,loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=84\n",
    "A=np.array(dataset_linear[i][1])\n",
    "B=np.array(dataset_linear[i][2])\n",
    "L=np.array(dataset_linear[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transferweights(L,A,B,n):\n",
    "    #train the A->B model\n",
    "    opt = tf.optimizers.SGD(1e-3)\n",
    "    mdn_PQ = MDN_module()\n",
    "    #calculate the prediction and the loss \n",
    "    mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "    withoutL=mdn_PQ.fit(x=reshapevar(A), y=B.T,epochs=100,batch_size=32,verbose=0)\n",
    "    y_pred = mdn_PQ.predict(reshapevar(A))\n",
    "    alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "            mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "            components_distribution=tfd.Normal(\n",
    "                loc=mu,       \n",
    "                scale=sigma))\n",
    "    log_likelihood = gm.log_prob(B).numpy()\n",
    "    loss_o = -tf.reduce_mean(log_likelihood, axis=-1).numpy()\n",
    "    #get the weights of A\n",
    "    weightofa=mdn_PQ.layers[0].get_weights()[0][0]\n",
    "    #get the bias\n",
    "    biasweight=mdn_PQ.layers[0].get_weights()[1]\n",
    "    #set the weights of L as zero \n",
    "    weightofL=np.zeros(15,dtype=np.float32)\n",
    "    #combine the weights of L and A\n",
    "    combinedweight=np.array([weightofL,weightofa])\n",
    "    #combine the weights and biases\n",
    "    layer0weightrans=[combinedweight,biasweight]\n",
    "    #only for one epoch just to get the weights \n",
    "    opt = tf.optimizers.SGD(1e-3)\n",
    "    mdn_trans = MDN_module()\n",
    "    mdn_trans.compile(loss=gnll_loss, optimizer=opt)\n",
    "    mdn_trans.fit(x=np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1), y=B.T,epochs=1,  batch_size=32,verbose=0)\n",
    "    y_pred = mdn_trans.predict(np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1))\n",
    "\n",
    "\n",
    "    mdn_trans.layers[0].set_weights(layer0weightrans)\n",
    "\n",
    "    a=mdn_PQ.layers[1].get_weights()\n",
    "    mdn_trans.layers[1].set_weights(a)  \n",
    "    a=mdn_PQ.layers[2].get_weights()\n",
    "    mdn_trans.layers[2].set_weights(a)  \n",
    "    a=mdn_PQ.layers[3].get_weights()\n",
    "    mdn_trans.layers[3].set_weights(a)  \n",
    "    a=mdn_PQ.layers[4].get_weights()\n",
    "    mdn_trans.layers[4].set_weights(a)  \n",
    "    a=mdn_PQ.layers[5].get_weights()\n",
    "    mdn_trans.layers[5].set_weights(a)  \n",
    "    #after setting the weights train it for 100 epochs with L also as input\n",
    "    mdn_trans.fit(x=np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1), y=B.T,epochs=100,  batch_size=32,verbose=0)\n",
    "    y_pred = mdn_trans.predict(np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1))\n",
    "    alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "            mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "            components_distribution=tfd.Normal(\n",
    "                loc=mu,       \n",
    "                scale=sigma))\n",
    "    log_likelihood = gm.log_prob(B).numpy()\n",
    "    loss_o_L= -tf.reduce_mean(log_likelihood, axis=-1).numpy()\n",
    "    trueloss= loss_o-loss_o_L\n",
    "\n",
    "    loss=[]\n",
    "    indices_1 = [i for i, x in enumerate(L) if x == 1]\n",
    "    #changin x==0 to x=-1\n",
    "    indices_0 = [i for i, x in enumerate(L) if x == 0]\n",
    "    for i in range(0,n):\n",
    "        B_dist_temp=np.zeros(len(B))\n",
    "        mod_indices_1=random.sample(indices_1,len(indices_1))\n",
    "        for i in range(len(indices_1)):\n",
    "            B_dist_temp[indices_1[i]]=B[mod_indices_1[i]]\n",
    "\n",
    "        mod_indices_0=random.sample(indices_0,len(indices_0))\n",
    "        for i in range(len(indices_0)):\n",
    "            B_dist_temp[indices_0[i]]=B[mod_indices_0[i]]\n",
    "\n",
    "\n",
    "        #train A-> Bstratified \n",
    "        opt = tf.optimizers.SGD(1e-3)\n",
    "        mdn_PQ = MDN_module()\n",
    "\n",
    "        mdn_PQ.compile(loss=gnll_loss, optimizer=opt)\n",
    "        withoutL=mdn_PQ.fit(x=reshapevar(A), y=B_dist_temp.T,epochs=100,batch_size=32,verbose=0)\n",
    "        y_pred_withoutL = mdn_PQ.predict(reshapevar(A))\n",
    "\n",
    "        alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "        gm = tfd.MixtureSameFamily(\n",
    "                mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "                components_distribution=tfd.Normal(\n",
    "                    loc=mu,       \n",
    "                    scale=sigma))\n",
    "        log_likelihood = gm.log_prob(B_dist_temp).numpy()\n",
    "        loss_o_strat= -tf.reduce_mean(log_likelihood, axis=-1).numpy()\n",
    "\n",
    "        #get the weights of A\n",
    "        weightofa=mdn_PQ.layers[0].get_weights()[0][0]\n",
    "        #get the bias\n",
    "        biasweight=mdn_PQ.layers[0].get_weights()[1]\n",
    "        #set the weights of L as zero \n",
    "        weightofL=np.zeros(15,dtype=np.float32)\n",
    "        #combine the weights of L and A\n",
    "        combinedweight=np.array([weightofL,weightofa])\n",
    "        #combine the weights and biases\n",
    "        layer0weightrans=[combinedweight,biasweight]\n",
    "\n",
    "        #only for one epoch just to get the weights \n",
    "        opt = tf.optimizers.SGD(1e-3)\n",
    "        mdn_trans = MDN_module()\n",
    "        mdn_trans.compile(loss=gnll_loss, optimizer=opt)\n",
    "        mdn_trans.fit(x=np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1), y=B_dist_temp.T,epochs=1,  batch_size=32,verbose=0)\n",
    "        y_pred = mdn_trans.predict(np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1))\n",
    "\n",
    "\n",
    "        mdn_trans.layers[0].set_weights(layer0weightrans)\n",
    "\n",
    "        a=mdn_PQ.layers[1].get_weights()\n",
    "        mdn_trans.layers[1].set_weights(a)  \n",
    "        a=mdn_PQ.layers[2].get_weights()\n",
    "        mdn_trans.layers[2].set_weights(a)  \n",
    "        a=mdn_PQ.layers[3].get_weights()\n",
    "        mdn_trans.layers[3].set_weights(a)  \n",
    "        a=mdn_PQ.layers[4].get_weights()\n",
    "        mdn_trans.layers[4].set_weights(a)  \n",
    "        a=mdn_PQ.layers[5].get_weights()\n",
    "        mdn_trans.layers[5].set_weights(a)  \n",
    "        #train it for 100 epochs after setting the weights \n",
    "\n",
    "        mdn_trans.fit(x=np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1), y=B_dist_temp.T,epochs=100,  batch_size=32,verbose=0)\n",
    "        y_pred = mdn_trans.predict(np.concatenate([L.reshape(-1,1),A.reshape(-1,1)],axis=1))\n",
    "\n",
    "        alpha,mu,sigma = slice_parameter_vectors(y_pred)\n",
    "        gm = tfd.MixtureSameFamily(\n",
    "                mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "                components_distribution=tfd.Normal(\n",
    "                    loc=mu,       \n",
    "                    scale=sigma))\n",
    "        log_likelihood = gm.log_prob(B_dist_temp).numpy()\n",
    "        loss_o_strat_L= -tf.reduce_mean(log_likelihood, axis=-1).numpy()\n",
    "        loss.append(loss_o_strat-loss_o_strat_L)\n",
    "    return trueloss,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "t,l=transferweights(L,A,B,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.43886173, 0.004278064]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.42293465,  0.66435575, -0.43240672, -0.32492578, -0.21821125,\n",
      "         0.11616646, -0.37854263, -0.44613716, -0.30665338,  0.2709536 ,\n",
      "        -0.20620054,  0.65273446,  0.00703361, -0.01296898, -0.63073564]],\n",
      "      dtype=float32), array([ 0.02432711,  0.07769597,  0.07965486, -0.04070804,  0.07460822,\n",
      "       -0.00273807,  0.00166281, -0.00847054,  0.0536484 , -0.01636308,\n",
      "        0.06164582,  0.03265581, -0.02191558, -0.03769946,  0.01689919],\n",
      "      dtype=float32)]\n",
      "[array([[-0.21171917,  0.16564627,  0.18720672,  0.12271357, -0.25353   ,\n",
      "        -0.05025075,  0.31149435,  0.15614106, -0.40629324, -0.42785066,\n",
      "         0.11770163, -0.42678604, -0.38949022, -0.3436387 ,  0.42561406],\n",
      "       [-0.37041807,  0.23908964,  0.53188574, -0.22524261,  0.1928842 ,\n",
      "         0.24730183,  0.07976234,  0.21775186,  0.4589229 , -0.29949242,\n",
      "         0.4822863 ,  0.16066045, -0.39576995, -0.4067981 ,  0.16247658],\n",
      "       [ 0.24039698, -0.3505851 , -0.2736759 ,  0.18426329,  0.41545448,\n",
      "        -0.04131916,  0.07280259, -0.22911663, -0.24574807, -0.3497989 ,\n",
      "        -0.21248625,  0.2642922 , -0.44482362,  0.37263379, -0.43486735],\n",
      "       [-0.3536238 , -0.28864086,  0.34939888, -0.13308534,  0.42319855,\n",
      "        -0.21052502,  0.21981457, -0.3801238 ,  0.31405753, -0.08200273,\n",
      "        -0.34502932, -0.3279686 , -0.23082045,  0.13711414,  0.18274935],\n",
      "       [-0.41693708,  0.02592396, -0.32022357,  0.19009453,  0.20825852,\n",
      "         0.15797804,  0.18260804, -0.33908424, -0.36906075,  0.03762382,\n",
      "         0.3329819 ,  0.33232677, -0.42546976, -0.04623231,  0.27345017],\n",
      "       [ 0.07374781, -0.34321892,  0.3788142 ,  0.3554784 , -0.44275627,\n",
      "         0.26415733,  0.1808324 , -0.37026066, -0.23111813,  0.3981582 ,\n",
      "        -0.18634519, -0.2984968 ,  0.05680341,  0.30557376, -0.35423234],\n",
      "       [-0.34156796,  0.42097455,  0.05006999, -0.14862335, -0.27351186,\n",
      "        -0.02745029, -0.08261528, -0.42207584,  0.36770323,  0.05555901,\n",
      "         0.13443363,  0.13500357,  0.23985088,  0.00844705,  0.20517471],\n",
      "       [-0.14013001,  0.24795286,  0.21549232, -0.14008307, -0.31696305,\n",
      "        -0.33238727,  0.0213389 ,  0.2644373 , -0.2420515 , -0.24250646,\n",
      "         0.08186887, -0.11838403, -0.15947628,  0.43810004,  0.25505167],\n",
      "       [ 0.36585775,  0.40471408,  0.3603181 , -0.4425568 ,  0.19865379,\n",
      "         0.32794863, -0.29013097,  0.37336332, -0.20313151,  0.0564774 ,\n",
      "        -0.38546768,  0.33526865, -0.03392383, -0.05235852, -0.02423576],\n",
      "       [-0.3535702 ,  0.4333674 ,  0.23124455, -0.12187797, -0.0654493 ,\n",
      "         0.28415656,  0.1829501 ,  0.35191512,  0.17596258, -0.14623645,\n",
      "        -0.35587856, -0.00501986,  0.09545887,  0.02240252, -0.22235768],\n",
      "       [-0.01801014, -0.43495506, -0.40460032, -0.3107891 , -0.28656277,\n",
      "        -0.05382589,  0.30294976, -0.3694942 , -0.27034935, -0.26520446,\n",
      "         0.14273109,  0.12607394, -0.05585873,  0.37159753, -0.0899439 ],\n",
      "       [-0.27912295, -0.226361  , -0.0359979 , -0.12478679, -0.2982035 ,\n",
      "         0.29377764,  0.38601196,  0.23035452,  0.1401571 ,  0.36697578,\n",
      "         0.51746964,  0.08217005,  0.29537892,  0.20271148,  0.3657818 ],\n",
      "       [-0.3482262 ,  0.275944  , -0.24155378, -0.01480463, -0.2884568 ,\n",
      "        -0.13015822, -0.23583831,  0.06006821,  0.12527402, -0.41402355,\n",
      "        -0.28882042,  0.28733587,  0.14629406,  0.09792393,  0.05583204],\n",
      "       [ 0.43263096, -0.25084263,  0.2374598 , -0.13043702, -0.28397414,\n",
      "        -0.41916502,  0.42093727, -0.25372154, -0.41790432, -0.18197736,\n",
      "        -0.35222426, -0.2565927 ,  0.31812525, -0.27613494, -0.10204234],\n",
      "       [ 0.3085814 ,  0.21362601, -0.19484173, -0.4446882 ,  0.13303682,\n",
      "         0.4650702 ,  0.40901744,  0.4343421 ,  0.3645326 , -0.24161519,\n",
      "         0.13213582,  0.24117859,  0.36948478,  0.3217898 , -0.12411974]],\n",
      "      dtype=float32), array([-4.56050523e-02, -2.48360429e-02,  6.32608011e-02,  0.00000000e+00,\n",
      "        6.49618218e-04, -7.92092551e-03, -4.98218508e-03,  2.12651771e-02,\n",
      "       -1.25863338e-02, -3.08877861e-05,  6.01236634e-02,  1.19488835e-01,\n",
      "        0.00000000e+00,  9.60891321e-02, -6.98124012e-03], dtype=float32)]\n",
      "[array([[ 0.20265448],\n",
      "       [-0.16611537],\n",
      "       [-0.44441468],\n",
      "       [-0.49136114],\n",
      "       [-0.29611742],\n",
      "       [-0.5863687 ],\n",
      "       [ 0.4709553 ],\n",
      "       [ 0.40039855],\n",
      "       [-0.3216092 ],\n",
      "       [-0.30950686],\n",
      "       [ 0.28177208],\n",
      "       [ 0.43228132],\n",
      "       [ 0.48693544],\n",
      "       [-0.28877035],\n",
      "       [ 0.27996463]], dtype=float32), array([0.], dtype=float32)]\n",
      "[array([[ 0.51478225],\n",
      "       [ 0.05627772],\n",
      "       [ 0.55554736],\n",
      "       [-0.21254835],\n",
      "       [-0.03782896],\n",
      "       [-0.22054026],\n",
      "       [ 0.17257036],\n",
      "       [ 0.21658719],\n",
      "       [ 0.18476798],\n",
      "       [ 0.2425124 ],\n",
      "       [ 0.5564285 ],\n",
      "       [-0.65951335],\n",
      "       [ 0.5349054 ],\n",
      "       [-0.50503385],\n",
      "       [ 0.05905953]], dtype=float32), array([-0.04946038], dtype=float32)]\n",
      "[array([[-0.18101282],\n",
      "       [ 0.56441116],\n",
      "       [ 0.00515363],\n",
      "       [ 0.2618184 ],\n",
      "       [ 0.13245836],\n",
      "       [ 0.47807   ],\n",
      "       [-0.20627135],\n",
      "       [-0.2165965 ],\n",
      "       [ 0.2396765 ],\n",
      "       [ 0.56502014],\n",
      "       [-0.4838169 ],\n",
      "       [ 0.27226695],\n",
      "       [-0.04596519],\n",
      "       [-0.27561608],\n",
      "       [ 0.39202186]], dtype=float32), array([-0.02452904], dtype=float32)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#for layer in mdn_PQ.layers:\n",
    "#    weights = layer.get_weights()\n",
    "#    print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4148914"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.6734492e-02, -3.0171201e-03, -1.0578049e-02,  1.2696251e-02,\n",
       "          8.5483119e-03, -9.5136967e-03, -3.8970541e-03, -8.0126990e-03,\n",
       "         -1.5199464e-02,  0.0000000e+00,  1.6920708e-02, -6.7785122e-03,\n",
       "          0.0000000e+00,  2.4403278e-02,  3.0928819e-02],\n",
       "        [-6.7548937e-01, -1.5555491e-01,  3.4730184e-01, -4.6164235e-01,\n",
       "          1.8827672e-01,  3.4252468e-01, -1.5349008e-01,  5.8932912e-01,\n",
       "          5.9475702e-01, -2.1092799e-03,  2.3663773e-01,  8.9469902e-02,\n",
       "         -6.0469005e-04, -2.2468133e-01, -2.7059579e-01]], dtype=float32),\n",
       " array([ 3.9699074e-02, -8.3049395e-05, -3.7667587e-02,  7.8542076e-02,\n",
       "         1.4809282e-02, -7.4501179e-02,  2.3135085e-02,  1.1343379e-01,\n",
       "         1.1295542e-02, -6.0940790e-03,  1.0466079e-02, -8.9767873e-03,\n",
       "        -2.0030746e-03,  1.3694398e-01,  1.2778476e-01], dtype=float32),\n",
       " array([[ 0.48548314,  0.31627208,  0.44611606,  0.15591282,  0.09881015,\n",
       "          0.10844085,  0.2499773 ,  0.06419306,  0.1696413 ,  0.08036657,\n",
       "          0.11597349, -0.11320528, -0.23710571, -0.04944052, -0.40310776],\n",
       "        [ 0.2035049 , -0.22230652, -0.28761384, -0.24746478,  0.05146884,\n",
       "         -0.18933636, -0.176321  , -0.27891967,  0.04066636, -0.05261499,\n",
       "         -0.09174632, -0.16498926,  0.20255774,  0.02076685,  0.41942143],\n",
       "        [ 0.19991136,  0.04131626,  0.07744717, -0.22410886, -0.0112587 ,\n",
       "          0.06377657, -0.24128677,  0.09969144, -0.2228609 , -0.17566603,\n",
       "         -0.09050805, -0.3223624 , -0.09757838, -0.28769326,  0.37653172],\n",
       "        [ 0.07187594, -0.0953058 ,  0.258418  , -0.40724933,  0.14141874,\n",
       "         -0.32919475,  0.17375126, -0.42337376, -0.11023878, -0.25061747,\n",
       "          0.2643791 , -0.31722343, -0.3518622 ,  0.31629658, -0.01657898],\n",
       "        [-0.30034047, -0.40417662,  0.2061027 , -0.03319627, -0.2611747 ,\n",
       "         -0.2503741 ,  0.44371015,  0.03338582,  0.15224482,  0.33227694,\n",
       "          0.27311733,  0.3681326 , -0.18792915, -0.15884519,  0.0312095 ],\n",
       "        [ 0.25700596, -0.18989189, -0.2276871 , -0.3557262 , -0.30771655,\n",
       "         -0.13780615, -0.3410378 , -0.44166246,  0.20138279, -0.05345926,\n",
       "          0.13955012, -0.06760412,  0.2061112 , -0.15068576, -0.01832988],\n",
       "        [ 0.03036062, -0.02223107,  0.35081375, -0.3045162 ,  0.41257906,\n",
       "          0.07392243,  0.17033437, -0.15626642, -0.06939159,  0.28343293,\n",
       "         -0.31789026, -0.3419488 ,  0.32893682, -0.445187  , -0.22302684],\n",
       "        [-0.17118372, -0.05865569,  0.10309878, -0.08568577,  0.2909105 ,\n",
       "          0.5270631 , -0.24614467,  0.08527177, -0.38641793,  0.15086623,\n",
       "          0.12880571, -0.3404597 , -0.31746358, -0.40545803,  0.53911775],\n",
       "        [ 0.12701574,  0.50157315, -0.27969682,  0.34238026, -0.2245411 ,\n",
       "          0.6297351 , -0.05135036,  0.05738912,  0.16881932, -0.02141965,\n",
       "         -0.35196415, -0.3391016 ,  0.30147308, -0.25138107, -0.25013417],\n",
       "        [-0.44567394,  0.13625677,  0.18282954,  0.35989952, -0.3160832 ,\n",
       "          0.10740395,  0.13422346, -0.15649551,  0.16057628,  0.14912146,\n",
       "          0.3188251 ,  0.09581268, -0.38713938,  0.41929397, -0.44553703],\n",
       "        [-0.12961918,  0.36278224,  0.38622314,  0.07193793,  0.3247063 ,\n",
       "          0.11829291,  0.01034254, -0.40612793, -0.29946315, -0.10695919,\n",
       "          0.02979938,  0.10353994,  0.01702645, -0.40404364,  0.27854815],\n",
       "        [-0.03065729, -0.10923666,  0.02481086, -0.43718395,  0.20088832,\n",
       "         -0.22996046,  0.09602004,  0.04991761,  0.08131715,  0.44001564,\n",
       "         -0.11682916,  0.30690032, -0.17458971,  0.27047032,  0.3277146 ],\n",
       "        [-0.14221361, -0.3008307 ,  0.34267014,  0.05034861, -0.43771887,\n",
       "          0.39800936,  0.11241052, -0.02247494,  0.29027522, -0.32267192,\n",
       "          0.09209245,  0.10420388, -0.21466115,  0.23549093, -0.318723  ],\n",
       "        [-0.31675932, -0.4223588 ,  0.40645477,  0.11338033,  0.4225258 ,\n",
       "          0.01431031, -0.1096289 ,  0.21568201, -0.3798564 ,  0.06083112,\n",
       "          0.41892204,  0.3134095 , -0.04570402, -0.31902662, -0.1094472 ],\n",
       "        [ 0.29126012, -0.04938457,  0.42356133,  0.15960348,  0.29107288,\n",
       "          0.11116406,  0.08596358,  0.03830612, -0.26313543, -0.0448488 ,\n",
       "          0.26579392, -0.26831412,  0.28034824,  0.0510202 ,  0.35212755]],\n",
       "       dtype=float32),\n",
       " array([-0.09248827, -0.0310035 ,  0.05706473,  0.06046672,  0.0097758 ,\n",
       "         0.11005363, -0.10364522, -0.01908577, -0.00449864,  0.04440515,\n",
       "         0.18183294,  0.        , -0.03920921, -0.0040364 ,  0.10618383],\n",
       "       dtype=float32),\n",
       " array([[ 0.2531864 ],\n",
       "        [ 0.03951138],\n",
       "        [-0.00559169],\n",
       "        [-0.52189887],\n",
       "        [ 0.14529622],\n",
       "        [ 0.36255193],\n",
       "        [-0.33391285],\n",
       "        [ 0.04046547],\n",
       "        [-0.22103786],\n",
       "        [-0.48783755],\n",
       "        [ 0.31723106],\n",
       "        [ 0.5238041 ],\n",
       "        [-0.3300866 ],\n",
       "        [-0.47744974],\n",
       "        [ 0.09985518]], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([[-0.28917903],\n",
       "        [ 0.5130085 ],\n",
       "        [-0.68198264],\n",
       "        [-0.52824783],\n",
       "        [-0.26834083],\n",
       "        [ 0.59507257],\n",
       "        [ 0.36482203],\n",
       "        [ 0.29603845],\n",
       "        [ 0.4848686 ],\n",
       "        [ 0.14244467],\n",
       "        [-0.55083257],\n",
       "        [ 0.3916512 ],\n",
       "        [-0.2740024 ],\n",
       "        [ 0.02434783],\n",
       "        [ 0.4399001 ]], dtype=float32),\n",
       " array([0.16614342], dtype=float32),\n",
       " array([[-0.04127028],\n",
       "        [ 0.49693346],\n",
       "        [-0.25230104],\n",
       "        [-0.40326363],\n",
       "        [ 0.6148771 ],\n",
       "        [ 0.01365515],\n",
       "        [ 0.2850021 ],\n",
       "        [-0.02806033],\n",
       "        [ 0.54954445],\n",
       "        [-0.10930916],\n",
       "        [-0.41149294],\n",
       "        [ 0.05729312],\n",
       "        [ 0.08809566],\n",
       "        [ 0.00541975],\n",
       "        [-0.28780672]], dtype=float32),\n",
       " array([0.12858579], dtype=float32)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdn_trans.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.19448982e-01, -1.73132129e+00, -2.60526056e-01,  1.15923766e+00,\n",
       "        2.11653083e+00,  1.23239404e+00,  1.69943019e+00, -1.11617911e+00,\n",
       "       -1.93419691e+00, -2.59800925e-01,  2.81483878e+00, -5.61159470e-01,\n",
       "       -1.30945375e+00,  5.94566884e-01,  2.08943845e+00,  4.16126532e-01,\n",
       "        1.74110054e-01,  1.28625280e+00,  1.97981724e+00,  1.79840950e+00,\n",
       "       -1.02302736e+00,  3.06032192e+00, -1.61209628e+00, -3.13207133e-01,\n",
       "       -6.97985793e-01, -8.00438727e-01, -6.01771665e-01, -9.85654068e-01,\n",
       "       -1.04709992e+00, -1.14912916e+00,  1.68272620e-01,  2.07574788e+00,\n",
       "        2.32972681e+00,  1.69075707e+00, -1.17354296e+00,  9.07793701e-02,\n",
       "        1.76722299e-01,  1.53721759e-01, -2.44414395e+00,  6.45270409e-01,\n",
       "       -2.83413921e-01,  9.24250952e-01,  1.43037776e+00, -3.11864210e+00,\n",
       "        6.80992195e-01,  6.80539814e-01, -1.06733095e+00,  1.67390677e+00,\n",
       "        2.60112691e-01,  1.83952381e+00,  2.06878452e-01, -9.26542588e-01,\n",
       "       -2.11359602e+00,  4.75593526e-01, -8.75947083e-01, -7.48536545e-01,\n",
       "        7.81651713e-01,  1.27184395e+00,  1.35052639e+00, -9.50527309e-01,\n",
       "       -2.07854958e+00,  1.01207466e+00, -8.04365451e-02, -9.41544137e-01,\n",
       "        1.35004752e+00, -2.56756605e+00,  9.68965884e-01, -4.99825937e-02,\n",
       "        3.84035319e+00, -1.13900745e+00,  5.44193405e-01, -2.40660585e+00,\n",
       "        2.27677278e-02, -4.53934627e-01,  5.24866437e-01, -1.08793773e-01,\n",
       "        1.45779603e+00,  4.95243862e-01,  2.29248800e+00, -1.26453803e+00,\n",
       "       -1.75615763e-01,  1.30079573e+00, -2.39520771e+00, -1.33489800e+00,\n",
       "       -9.92216556e-01, -1.50154213e+00,  8.91602037e-01, -2.10136922e-01,\n",
       "        1.07362916e-02, -3.21925201e-01, -1.07031695e+00, -3.81093923e-01,\n",
       "       -3.02470114e+00,  2.18830751e+00,  5.95156122e-01,  2.06073402e+00,\n",
       "       -1.18014849e+00, -9.67870507e-01, -7.21299555e-01,  2.66995517e+00,\n",
       "        9.45124144e-01, -2.40532121e+00,  9.81654827e-01,  2.92287781e-01,\n",
       "        1.88599381e+00, -6.98895175e-01,  2.61382366e+00, -1.80684438e-01,\n",
       "        6.42056252e-01, -5.58878261e-01,  1.91434403e+00,  1.00823930e+00,\n",
       "        1.03054338e+00,  1.01979124e+00, -4.98025236e-01,  1.57547962e+00,\n",
       "        4.68346070e-01,  3.38164659e-01, -2.79830773e-01,  1.24212696e+00,\n",
       "        9.84246923e-01, -6.00653456e-01,  3.43488620e+00, -1.02960660e+00,\n",
       "        1.59513420e+00,  8.54865849e-01, -1.89608125e+00,  1.11881682e+00,\n",
       "        1.56518686e+00,  9.48815252e-01, -6.53064847e-01,  2.20125580e+00,\n",
       "        3.70396173e-01, -1.11693510e-01, -1.31093569e-01, -2.26889908e-01,\n",
       "        2.92843561e+00, -1.63380108e+00, -7.27650373e-01,  2.54418143e+00,\n",
       "       -7.73975537e-01,  2.04792478e+00,  6.79239808e-01, -3.27154511e-01,\n",
       "        4.17484182e-01,  1.68921526e+00, -1.47435650e-01,  1.96583192e+00,\n",
       "        1.41169127e+00, -1.59840516e+00,  2.43918749e+00, -1.18787541e+00,\n",
       "        5.11189705e-01, -4.23034950e-01,  1.87360000e+00,  1.26518780e+00,\n",
       "       -6.18976232e-02,  5.12765313e-01, -9.11316296e-01, -9.17804009e-01,\n",
       "       -8.64878240e-01,  1.14799462e-01,  5.90427867e-01, -5.07885335e-01,\n",
       "       -1.53435543e+00,  6.42767377e-01, -1.01639320e+00,  1.02921960e+00,\n",
       "        1.61047320e+00, -6.82019430e-01,  6.33676366e-01, -1.16232867e+00,\n",
       "        3.71526720e+00, -5.33414280e-01,  1.76934634e-01,  1.33521135e+00,\n",
       "        8.70051284e-01,  4.79498834e-01, -7.62827556e-01,  1.53308829e+00,\n",
       "        2.56604151e+00, -1.38572667e+00,  9.78447059e-01,  4.07610524e-01,\n",
       "       -4.89525095e-01, -5.87831894e-02, -2.00374109e+00, -1.27357581e+00,\n",
       "       -5.03062608e-01,  2.33598150e+00,  4.34660412e-01,  3.04883098e+00,\n",
       "       -8.03313962e-01,  6.60138249e-01,  8.67899857e-01, -1.38518817e+00,\n",
       "       -7.20534888e-02,  1.10079756e+00, -2.07749847e+00, -9.43911472e-01,\n",
       "       -1.30365766e-01,  2.18481040e-01,  1.52691261e+00, -6.51520880e-01,\n",
       "        1.99388584e+00, -1.85296122e+00,  4.70564726e-01, -2.27849666e-01,\n",
       "        9.17619737e-01,  5.08540393e-01, -1.31928498e-01, -2.22968400e+00,\n",
       "        2.35950829e+00,  1.15659488e+00, -3.23544399e-01, -1.17972204e+00,\n",
       "       -6.51666986e-01, -5.13045268e-01,  8.71621021e-01,  9.36215522e-02,\n",
       "        1.63115193e+00, -1.74210273e+00, -6.21694858e-01, -1.70964680e+00,\n",
       "       -6.66469785e-01,  7.88439583e-01,  3.75266039e-01,  2.03854961e+00,\n",
       "        8.90365858e-01, -7.01581315e-01,  2.25512515e-01,  8.53442579e-01,\n",
       "       -2.09711752e+00, -7.53245624e-01, -1.26029149e+00,  2.11088876e+00,\n",
       "        1.98159765e-01,  5.30620901e-01,  8.02844309e-02,  1.36546013e+00,\n",
       "        1.49857868e+00,  3.56617811e-01,  2.00078968e+00,  4.86967120e-01,\n",
       "       -4.54824491e-01,  3.14229963e+00,  2.24487777e+00,  3.14353454e+00,\n",
       "        1.33404570e+00,  1.40340385e+00,  3.39083088e-01,  1.22159606e+00,\n",
       "       -1.63858536e-01, -3.19188370e+00,  6.49609413e-01,  1.82700464e+00,\n",
       "       -1.62955351e-01,  9.99484826e-01, -8.13749110e-01,  1.52058102e+00,\n",
       "       -2.08094161e-01,  1.19809286e-02, -3.91847139e-01,  3.15438310e+00,\n",
       "        1.87778085e+00,  1.22680939e+00,  1.02348384e+00, -1.60924068e+00,\n",
       "       -2.33495714e-02,  1.39681123e+00,  1.05834005e+00,  1.55216821e+00,\n",
       "       -1.03969545e+00, -1.92241830e-01, -2.58475045e-02,  1.25790399e+00,\n",
       "       -4.58579862e-01, -1.68200671e+00,  1.30424381e-01,  3.16955968e-01,\n",
       "       -2.28753245e-01, -1.00610526e+00,  2.62379793e+00, -2.80780425e-01,\n",
       "       -1.89822305e+00, -3.91556107e-03,  1.06485591e+00,  7.03569637e-01,\n",
       "        1.50835090e+00, -1.83034418e+00,  1.29190563e+00,  1.13003634e+00,\n",
       "       -3.11406113e-01,  1.87039583e+00,  3.12226110e+00, -3.32086163e-01,\n",
       "       -9.75715247e-01,  1.73796877e+00, -1.44832352e+00, -1.49034297e+00,\n",
       "        1.58429432e+00, -9.66823093e-01,  1.44553581e+00, -1.42469872e-01,\n",
       "       -7.11808003e-01,  1.54814044e+00,  9.78272255e-01, -1.79512713e+00,\n",
       "        1.94578555e+00,  1.39170852e+00, -1.25382152e+00, -2.11292911e+00,\n",
       "        1.23144699e+00,  1.10442715e+00,  2.23343307e+00,  1.20014111e+00,\n",
       "        8.14403861e-01, -9.05204187e-02,  1.02980491e+00,  4.95744912e-02,\n",
       "       -1.76110994e+00, -2.18941183e+00,  2.62546897e+00, -8.63078385e-01,\n",
       "        2.22385592e+00, -2.34178145e-01,  1.75924586e+00, -1.47468080e+00,\n",
       "       -5.08066302e-01,  4.47261549e-02,  1.12246721e-02, -1.00455371e+00,\n",
       "       -7.31580191e-01,  2.86685101e-01,  6.94261022e-01, -1.56378040e-01,\n",
       "        1.02011806e-01, -5.13388571e-01, -2.40790143e+00, -1.40432466e+00,\n",
       "        4.93923719e-01,  2.45852274e-01,  9.10751175e-01,  6.73389860e-01,\n",
       "        1.51432043e-02,  6.58440821e-01,  7.77187550e-01,  2.93497655e+00,\n",
       "        2.09858157e-01,  7.63546122e-01,  2.62973032e+00, -1.40867952e+00,\n",
       "        6.62293152e-01, -8.76825641e-01, -1.47519546e-01,  6.40915079e-01,\n",
       "        9.35923136e-01,  3.07896180e+00,  2.38520533e+00, -1.32798705e+00,\n",
       "       -1.73524936e+00, -1.19584272e+00,  1.99775279e+00,  7.22786631e-01,\n",
       "        3.32678828e+00,  1.65710029e+00, -2.20822560e-02, -6.18676967e-01,\n",
       "        1.52570810e+00, -1.83282303e+00,  1.27064460e+00,  3.21870942e+00,\n",
       "        2.23375967e-02,  1.45190522e+00,  1.02042585e+00, -2.15024016e+00,\n",
       "       -1.01394462e+00,  1.01905183e+00,  2.62484862e+00, -8.38418293e-01,\n",
       "       -1.68971231e+00,  1.69565635e+00, -8.28748219e-01,  1.48506539e+00,\n",
       "       -3.74674355e-01,  1.80066919e+00, -2.84460026e-01, -4.39757061e-01,\n",
       "        1.89478099e+00,  6.70266687e-01, -2.36957897e+00,  1.50672292e+00,\n",
       "        1.35330321e+00,  4.70041628e-01,  1.20487039e+00, -8.48565144e-01,\n",
       "       -5.40825515e-01, -1.10242021e+00, -8.28862493e-01,  2.18613140e+00,\n",
       "       -1.16926907e-01,  1.47726681e-01, -1.16996698e+00,  4.75440304e-01,\n",
       "        7.57585561e-01,  1.18501908e+00, -1.22966708e+00, -6.64876160e-01,\n",
       "       -7.56222158e-01,  3.75706650e+00, -1.37103112e+00, -7.04797549e-01,\n",
       "       -6.68556848e-03,  1.77788532e+00, -2.28358986e-01,  3.20603050e-01,\n",
       "       -1.28467808e+00,  2.09936302e+00,  1.42574029e+00,  1.43894823e+00,\n",
       "        2.61682381e+00,  3.36322372e-01,  5.66735533e-01,  1.57364668e+00,\n",
       "       -2.07251125e-01,  4.09803161e-01,  1.77829740e+00, -5.86881959e-01,\n",
       "        2.72157472e-02,  9.73599104e-01, -1.75517029e-01, -9.63257245e-01,\n",
       "       -3.72032884e-01,  3.99194934e-01,  1.01317086e+00,  2.79987149e-01,\n",
       "        6.72192852e-03,  1.32676785e+00,  1.29225330e+00,  1.18171842e+00,\n",
       "        3.00739622e+00,  1.52526971e+00, -1.17004779e+00, -2.97163749e+00,\n",
       "       -2.82187587e+00, -1.41370988e+00,  1.24854010e+00,  7.15144692e-01,\n",
       "        4.85713300e-01,  1.43621946e+00, -1.00448809e+00, -1.19019872e-01,\n",
       "       -8.09274037e-01,  5.35230528e-01,  1.50397335e-01,  6.07062440e-01,\n",
       "        1.22307459e+00, -5.55479160e-01,  5.11909146e-02,  1.60452248e+00,\n",
       "       -1.15667328e+00, -5.45272741e-01,  2.43058900e-01,  2.71891743e-01,\n",
       "       -4.19397705e-01,  2.26666258e+00,  1.10394140e+00, -1.21593682e+00,\n",
       "       -1.85439959e+00, -2.35395139e+00,  1.40816393e+00,  2.47362212e+00,\n",
       "       -3.01019388e+00, -1.79328699e+00,  4.60722439e-01,  2.68915598e-01,\n",
       "       -7.02857916e-01,  2.20243676e-02,  5.33080466e-01,  1.55745038e+00,\n",
       "       -2.02589659e+00,  4.75764561e-01, -1.00881185e+00,  1.33004311e+00,\n",
       "       -9.97091555e-01,  2.83289886e+00, -2.63966523e+00, -1.39983560e+00,\n",
       "       -1.21777948e+00,  2.42356968e+00,  2.15631842e+00,  6.00477095e-01,\n",
       "        2.03500149e+00, -3.64706663e-01, -1.96134868e+00,  2.79749223e-02,\n",
       "       -4.75068180e-01, -2.56715662e-01,  2.42095121e+00,  1.70912770e+00,\n",
       "        2.35552144e-01,  1.73145120e+00, -1.70436523e-01, -8.78891911e-01,\n",
       "       -1.95078446e+00,  2.45684161e+00,  4.46131737e-01,  1.95784237e-01,\n",
       "       -5.97221617e-01,  3.70448480e-01,  7.46158528e-01, -3.64559773e-01,\n",
       "        2.08369894e+00,  2.32762687e+00,  6.46134478e-01, -1.94419080e-01,\n",
       "       -7.00633676e-01,  9.93746638e-02,  1.63996071e+00,  8.43316400e-01,\n",
       "       -4.08731481e-01,  2.70495628e+00,  2.52516587e+00, -5.93460692e-01,\n",
       "        2.96114846e-01,  2.54151026e+00,  1.82567585e-01,  1.10588523e+00,\n",
       "        9.45273663e-01,  1.28995134e+00,  2.74901540e-01,  1.28022529e+00,\n",
       "        1.07607062e-01,  2.38643340e-01, -4.19008819e-01, -1.51959557e+00,\n",
       "        1.23772155e+00,  1.48474551e+00,  1.68536130e+00, -6.09289680e-01,\n",
       "        7.98086837e-01,  1.32412644e+00,  1.07222656e+00,  2.75063215e+00,\n",
       "        2.11429558e+00, -1.65076861e+00,  1.50600742e-01, -4.33276168e-01,\n",
       "        2.69328317e+00,  9.40287145e-01,  7.82463572e-01, -9.63563932e-02,\n",
       "        5.71100630e-01,  6.59494888e-01, -7.38890078e-02,  1.04134796e+00,\n",
       "        5.21247991e-02,  3.64427621e-01,  1.75209761e+00,  2.55901524e-01,\n",
       "        6.14357144e-01,  9.06622459e-01,  2.34961962e+00, -7.01937389e-01,\n",
       "       -3.47832512e-01, -1.67340022e-01,  1.96116863e+00,  1.01648387e+00,\n",
       "        1.85462476e+00,  1.23681699e-01,  1.90314318e+00, -2.77548847e+00,\n",
       "        1.46513666e+00, -4.43505017e-01, -1.63166530e-01, -6.51761692e-01,\n",
       "        1.42886846e-01, -9.42335839e-01, -5.02326629e-01,  1.32195847e+00,\n",
       "        3.51367503e-01, -8.07303671e-02,  1.60219590e-01, -4.89392086e-02,\n",
       "        2.86389604e-01,  6.67103773e-01, -4.11362956e-01, -2.36079272e-01,\n",
       "       -4.26464490e-01, -4.58493298e-01,  3.72357248e-01,  5.14766984e-02,\n",
       "       -2.76147825e+00,  2.12933087e+00,  2.70728688e+00,  1.33035890e+00,\n",
       "       -5.07172536e-01, -2.66366416e+00, -4.02516663e-01,  2.74728928e-01,\n",
       "       -3.74413225e-01,  2.91287463e-01,  6.28539387e-01,  5.37434354e-01,\n",
       "        6.19358148e-01, -1.52927332e+00,  2.30031364e+00,  2.20346497e+00,\n",
       "        1.21402629e+00, -9.06546977e-01,  3.67234025e-01,  1.21792380e+00,\n",
       "       -7.15606243e-01, -1.46422164e+00, -1.10490928e+00, -1.32740692e+00,\n",
       "        9.03556537e-01,  1.60919266e+00, -4.85245399e-01, -5.08104702e-01,\n",
       "        1.63666630e+00, -6.22252821e-03, -7.86943611e-01,  5.64154956e-01,\n",
       "       -4.18152483e-01, -2.48882584e+00,  2.45365499e-01,  1.56763683e+00,\n",
       "       -1.50887972e+00,  7.03669592e-01,  2.88837920e-01,  4.40207687e-02,\n",
       "        1.83382220e+00,  1.96030014e+00,  7.69906463e-01, -7.79918877e-01,\n",
       "        3.02366594e-02, -2.04481986e-01,  1.96286748e-01,  5.52086630e-01,\n",
       "       -4.49214892e-01,  1.11505473e+00,  4.98669435e-01, -7.50905287e-01,\n",
       "       -2.05053105e-01,  6.02550714e-01,  1.58303076e+00,  7.56425076e-01,\n",
       "       -4.43962262e-01,  1.48798378e+00,  1.65593292e+00,  2.60543394e-01,\n",
       "       -1.16007672e+00,  2.80773297e+00, -1.67138745e+00,  3.70670975e-03,\n",
       "        7.72245324e-01,  9.03536215e-01, -3.63570491e+00, -5.80644909e-01,\n",
       "        9.03660136e-01,  7.46459653e-01,  3.41349576e+00,  2.60626979e+00,\n",
       "        9.81326663e-01,  5.98209962e-01, -4.54901867e-01, -1.00046452e+00,\n",
       "        4.41555165e-01, -1.40366513e+00,  1.46588694e+00,  1.24458446e+00,\n",
       "        2.63036211e+00, -9.84046952e-05, -1.88086104e+00, -8.50921111e-01,\n",
       "       -4.56761111e-01,  3.93997347e-01,  3.22729939e-01, -1.31440689e+00,\n",
       "        2.97383248e+00,  5.63000183e-01, -1.26091896e+00,  6.83940516e-01,\n",
       "       -2.28056894e+00, -1.39952925e+00, -5.98908592e-01,  1.91878807e+00,\n",
       "       -1.52238232e+00,  7.00877151e-01, -1.50824503e-01,  2.87193233e-01,\n",
       "        9.55325114e-02, -1.01505104e+00,  4.43939854e-01, -8.42503629e-01,\n",
       "       -1.06933985e+00,  1.72541864e+00, -8.25446651e-01,  1.84689407e-02,\n",
       "       -1.49927360e+00,  2.12366270e+00, -2.21748914e+00,  2.17053302e+00,\n",
       "       -3.44089511e-01,  3.61831351e-01, -4.61065653e-01, -4.29323139e-01,\n",
       "        7.84995475e-01,  7.65579011e-01,  3.44303402e-01,  1.89920341e+00,\n",
       "        5.35232336e-01,  6.41390095e-01,  7.45925384e-01,  9.67825968e-01,\n",
       "        3.02353072e+00,  1.80492749e+00,  9.70606763e-01,  2.65669752e-01,\n",
       "       -1.89133593e+00,  3.61223703e-01,  1.48149302e+00,  5.44731672e-01,\n",
       "        2.97096403e+00,  1.12009813e+00,  1.59970118e+00,  5.43111296e-01,\n",
       "       -2.28204392e+00,  4.98359157e-01,  9.89205711e-01,  1.04092952e+00,\n",
       "       -1.16637023e-01,  2.68188208e+00, -5.28021477e-01, -5.15563348e-01,\n",
       "       -1.23399085e+00,  1.69789042e-01, -7.08139563e-01,  5.94888303e-02,\n",
       "       -9.36774056e-01, -1.65551646e+00, -1.30836601e-02, -9.67672507e-01,\n",
       "        5.24900068e-01,  4.97144802e-01,  1.89967430e+00, -1.50240394e+00,\n",
       "       -3.52036901e-01,  4.41087944e+00, -9.01599762e-01,  5.20240398e-01,\n",
       "       -2.63785843e-02,  1.23699935e+00,  2.17923845e+00, -6.23069335e-01,\n",
       "       -1.97107702e-01, -1.78176422e+00,  1.17020501e+00, -4.73233725e-01,\n",
       "       -2.23633402e-01,  1.43386294e+00,  1.13060511e-01, -1.18536374e+00,\n",
       "       -2.19818320e+00, -5.99833317e-01,  9.32729036e-01, -2.28835294e+00,\n",
       "        1.16607928e+00, -2.10754889e+00, -2.81672054e-01,  3.89935729e+00,\n",
       "        2.80866564e+00, -3.70356155e-01,  1.72502593e+00,  8.35781841e-01,\n",
       "       -6.86627105e-01, -1.44599828e+00,  4.80273228e-01,  2.07867413e+00,\n",
       "        8.12168694e-01,  1.34584809e+00,  2.85117657e+00,  4.32693877e-01,\n",
       "        1.64690302e+00, -1.90026604e-01, -7.15576010e-01, -2.21184165e+00,\n",
       "       -2.32988096e+00, -1.20910360e+00,  8.78333387e-01, -6.80692692e-01,\n",
       "        1.21482659e+00, -1.33917038e+00, -1.49978118e+00, -2.55960060e+00,\n",
       "       -1.01050893e+00,  9.15597416e-01, -3.47473091e+00,  4.56834649e-02,\n",
       "       -2.05665601e-01, -9.48906423e-01, -6.53127340e-01,  1.52659765e+00,\n",
       "       -2.33261498e+00,  1.28149589e-01,  3.66529268e-01,  1.65524559e+00,\n",
       "       -1.64418152e-01,  1.30730391e-01,  1.12862855e+00,  9.07770561e-01,\n",
       "        1.04704897e+00,  5.09222071e-01,  1.21337699e+00, -7.02907421e-01,\n",
       "       -7.62116771e-01,  1.48649258e+00,  5.05957787e-01, -1.13512794e+00,\n",
       "        1.88299817e+00, -1.18270583e+00,  1.09312393e+00,  9.70004523e-01,\n",
       "        1.67848766e+00, -2.52344626e+00,  4.79316126e-01,  6.74698553e-01,\n",
       "        7.51186159e-01, -2.16137948e+00, -9.22898041e-01, -2.42088203e+00,\n",
       "       -1.25642834e+00, -7.13994041e-01, -5.38041643e-01,  7.00499395e-01,\n",
       "       -1.13504605e-01,  2.17231160e+00,  6.84981564e-01,  5.84371114e-02,\n",
       "        4.85698556e-02,  3.90264684e-01,  7.88927553e-01,  6.64352944e-01,\n",
       "       -1.56826893e+00,  1.76357350e+00,  1.60261429e-01, -8.57447303e-02,\n",
       "       -2.42309901e+00,  2.22723196e+00,  1.10414340e+00, -4.49179624e-01,\n",
       "        2.87580435e+00, -5.73122981e-01,  1.93775989e+00,  1.59042299e+00,\n",
       "       -3.85751023e-01,  5.22020574e-01, -1.38821734e+00,  4.48803672e-01,\n",
       "       -1.73985642e+00,  2.69068288e+00, -9.68531618e-01,  1.22394076e-01,\n",
       "       -1.50271605e+00,  3.09922777e-02, -1.69736008e+00, -1.25574361e+00,\n",
       "        3.84097203e-01,  7.40661595e-01,  2.25562648e+00,  8.30729201e-01,\n",
       "        1.70879796e+00,  1.88755857e-02, -5.69832266e-01, -1.96239371e+00,\n",
       "        2.10054876e+00,  2.85968658e-02,  2.93307498e+00,  4.17370212e-01,\n",
       "        3.55987663e+00, -1.03226986e+00,  2.97704209e-01,  1.68740722e+00,\n",
       "        1.16307780e+00,  1.25660871e+00,  1.26036387e+00, -1.49795197e-01,\n",
       "       -7.93157543e-01,  3.52019399e-01,  3.24895148e-01,  3.31546104e-01,\n",
       "       -1.01133266e-01, -9.58895825e-01,  2.07033013e+00, -2.69228383e+00,\n",
       "        1.11020180e+00, -2.46338644e+00,  3.60934136e-01, -2.15523165e+00,\n",
       "        3.48627388e-01, -9.18784728e-01,  2.07099532e+00, -4.79738418e-01,\n",
       "        1.36281469e+00,  1.42179116e+00, -1.97872154e-01,  1.46418902e+00,\n",
       "       -1.10205449e+00, -1.65233692e-01, -2.76386159e-01,  2.27953116e+00,\n",
       "       -1.00607123e+00, -2.63942611e+00,  2.52794600e+00,  7.99514935e-01,\n",
       "        3.91319556e-01, -1.61784959e+00,  9.14834574e-02,  4.49901687e-01,\n",
       "        5.50573274e+00,  4.30564238e-01, -5.81411886e-01,  6.66929854e-01,\n",
       "        6.32170861e-01,  1.10669824e+00,  6.69440499e-02, -1.32669799e-01,\n",
       "       -9.38522699e-02,  7.67617256e-01,  1.15649270e+00,  4.51122002e-01,\n",
       "       -3.58859882e+00, -8.14426737e-01,  1.05582315e+00, -1.90631723e-01,\n",
       "        1.74127643e+00,  5.83094573e-01,  1.03504028e+00, -8.02572528e-01,\n",
       "        1.79354654e+00,  1.44595176e+00,  9.79174588e-02,  3.47404247e+00,\n",
       "        1.92708749e+00,  2.10397068e+00, -4.57962696e-01, -4.64941581e-01,\n",
       "       -1.20751173e+00, -2.21340263e+00, -1.06448673e+00, -2.74086339e-01,\n",
       "        1.25976976e+00,  1.08311983e+00, -4.40670615e-01,  7.83034261e-01,\n",
       "       -1.15368299e+00, -1.24542290e+00,  1.02989401e-01,  2.03680735e+00,\n",
       "        6.51445833e-03, -1.57952522e+00, -9.71053287e-01,  8.08788196e-01,\n",
       "       -1.07307111e-01, -1.40956073e+00,  1.05653493e+00,  8.19717136e-01,\n",
       "        1.06750946e+00, -8.55235997e-01,  1.27365671e+00,  1.71581713e-01,\n",
       "        9.67035700e-01,  2.17909555e+00, -9.14250532e-01,  1.61994357e-01,\n",
       "       -7.32295972e-01,  2.56144539e-01,  7.55894648e-01,  4.49332767e-01,\n",
       "        7.40906658e-01,  2.28450936e+00,  1.53936333e+00,  1.11907752e+00,\n",
       "       -8.11096645e-01,  1.79729013e+00, -1.37901835e-01,  1.03606040e+00,\n",
       "        5.53611692e-01,  8.59298431e-02,  2.62720830e-01, -7.62147478e-02,\n",
       "        4.02238169e+00, -1.77092677e+00,  2.20079506e-01, -5.14152965e-01,\n",
       "        4.21521515e-01,  2.11804154e+00,  3.31329967e+00,  9.91119301e-03])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_dist_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1771035"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7162725"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CITNonLinear.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
